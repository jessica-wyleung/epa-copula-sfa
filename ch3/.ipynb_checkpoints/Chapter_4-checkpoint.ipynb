{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1224d3cc",
   "metadata": {},
   "source": [
    "# Basics of stochastic frontier analysis for panel data (Chapter 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c05249c",
   "metadata": {},
   "source": [
    "## Exercise 4.1: Within and Between Summary Statistics\n",
    "\n",
    "This exercise reports summary statistics for the between and within variation of log GPD from the _WBpanel.csv_ data as well as the correlations of log GDP with itself lagged once, twice and three times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "999e892d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std. Dev</th>\n",
       "      <th>Min</th>\n",
       "      <th>Max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>2.778852</td>\n",
       "      <td>1.921035</td>\n",
       "      <td>-1.31903</td>\n",
       "      <td>8.401306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Between</th>\n",
       "      <td>None</td>\n",
       "      <td>1.885078</td>\n",
       "      <td>-0.844032</td>\n",
       "      <td>8.009964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Within</th>\n",
       "      <td>None</td>\n",
       "      <td>0.369944</td>\n",
       "      <td>1.67231</td>\n",
       "      <td>3.942549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Mean  Std. Dev       Min       Max\n",
       "Overall  2.778852  1.921035  -1.31903  8.401306\n",
       "Between      None  1.885078 -0.844032  8.009964\n",
       "Within       None  0.369944   1.67231  3.942549"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "WBpanel = pd.read_csv(\"WBpanel.csv\")\n",
    "\n",
    "overall_stats = [\n",
    "    np.mean(WBpanel[\"lny\"]),\n",
    "    np.std(WBpanel[\"lny\"]),\n",
    "    np.min(WBpanel[\"lny\"]),\n",
    "    np.max(WBpanel[\"lny\"]),\n",
    "]\n",
    "\n",
    "# Within and between variation for log GDP\n",
    "group_means = WBpanel.groupby([\"country\"], as_index=False)[\"lny\"].mean()\n",
    "group_means.rename(columns={\"lny\": \"lny_bar\"}, inplace=True)\n",
    "WBpanel = WBpanel.merge(group_means, how=\"left\", on=[\"country\"])\n",
    "within_lny_data = WBpanel[\"lny\"] - WBpanel[\"lny_bar\"] + np.mean(WBpanel[\"lny\"])\n",
    "within_stats = [\n",
    "    None,\n",
    "    np.std(within_lny_data),\n",
    "    np.min(within_lny_data),\n",
    "    np.max(within_lny_data),\n",
    "]\n",
    "\n",
    "between_stats = [\n",
    "    None,\n",
    "    np.std(group_means[\"lny_bar\"]),\n",
    "    np.min(group_means[\"lny_bar\"]),\n",
    "    np.max(group_means[\"lny_bar\"]),\n",
    "]\n",
    "\n",
    "all_stats = np.array([overall_stats, between_stats, within_stats])\n",
    "panel_summary_statistics = pd.DataFrame(\n",
    "    all_stats,\n",
    "    columns=[\"Mean\", \"Std. Dev\", \"Min\", \"Max\"],\n",
    "    index=[\"Overall\", \"Between\", \"Within\"],\n",
    ")\n",
    "display(panel_summary_statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abd4ae36",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lny</th>\n",
       "      <th>lny_lag1</th>\n",
       "      <th>lny_lag2</th>\n",
       "      <th>lny_lag3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lny</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999576</td>\n",
       "      <td>0.999006</td>\n",
       "      <td>0.998384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lny_lag1</th>\n",
       "      <td>0.999576</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999566</td>\n",
       "      <td>0.998988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lny_lag2</th>\n",
       "      <td>0.999006</td>\n",
       "      <td>0.999566</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lny_lag3</th>\n",
       "      <td>0.998384</td>\n",
       "      <td>0.998988</td>\n",
       "      <td>0.999558</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               lny  lny_lag1  lny_lag2  lny_lag3\n",
       "lny       1.000000  0.999576  0.999006  0.998384\n",
       "lny_lag1  0.999576  1.000000  0.999566  0.998988\n",
       "lny_lag2  0.999006  0.999566  1.000000  0.999558\n",
       "lny_lag3  0.998384  0.998988  0.999558  1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create lags of GDP\n",
    "lag_WBpanel = []\n",
    "for country, group in WBpanel.groupby(\"country\", as_index=False):\n",
    "    for i in range(1, 4):\n",
    "        group[f\"lny_lag{i}\"] = group[\"lny\"].shift(i)\n",
    "    lag_WBpanel.append(group)\n",
    "lag_WBpanel = pd.concat(lag_WBpanel, axis=0)\n",
    "serial_correlation_matrix = lag_WBpanel[\n",
    "    [\"lny\", \"lny_lag1\", \"lny_lag2\", \"lny_lag3\"]\n",
    "].corr()\n",
    "\n",
    "display(serial_correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ca21235",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])?  y\n"
     ]
    }
   ],
   "source": [
    "# Remove all previous function and variable definitions before the next exercise\n",
    "%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6258c8e",
   "metadata": {},
   "source": [
    "## Exercise 4.2: Fixed Effects Regression\n",
    "\n",
    "This exercise implements a fixed effects (within) panel regression model for the _WBpanel.csv_. We report cluster robust standard errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d26f6207",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          PanelOLS Estimation Summary                           \n",
      "================================================================================\n",
      "Dep. Variable:                    lny   R-squared:                        0.8934\n",
      "Estimator:                   PanelOLS   R-squared (Between):              0.8380\n",
      "No. Observations:                2296   R-squared (Within):               0.8934\n",
      "Date:                Mon, Mar 13 2023   R-squared (Overall):              0.8401\n",
      "Time:                        14:25:57   Log-likelihood                    1594.7\n",
      "Cov. Estimator:             Clustered                                           \n",
      "                                        F-statistic:                      6173.6\n",
      "Entities:                          82   P-value                           0.0000\n",
      "Avg Obs:                       28.000   Distribution:                  F(3,2211)\n",
      "Min Obs:                       28.000                                           \n",
      "Max Obs:                       28.000   F-statistic (robust):             514.70\n",
      "                                        P-value                           0.0000\n",
      "Time periods:                      28   Distribution:                  F(3,2211)\n",
      "Avg Obs:                       82.000                                           \n",
      "Min Obs:                       82.000                                           \n",
      "Max Obs:                       82.000                                           \n",
      "                                                                                \n",
      "                             Parameter Estimates                              \n",
      "==============================================================================\n",
      "            Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
      "------------------------------------------------------------------------------\n",
      "intercept      0.5099     0.1793     2.8443     0.0045      0.1583      0.8614\n",
      "lnk            0.5315     0.0514     10.341     0.0000      0.4307      0.6323\n",
      "lnl            0.1336     0.1094     1.2222     0.2218     -0.0808      0.3481\n",
      "yr             0.0075     0.0029     2.5386     0.0112      0.0017      0.0132\n",
      "==============================================================================\n",
      "\n",
      "F-test for Poolability: 211.15\n",
      "P-value: 0.0000\n",
      "Distribution: F(81,2211)\n",
      "\n",
      "Included effects: Entity\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from linearmodels import PanelOLS\n",
    "from scipy import stats\n",
    "\n",
    "regression_data = pd.read_csv(\"WBpanel.csv\")\n",
    "\n",
    "# Fixed effects model using the linearmodels python package\n",
    "regression_data = pd.read_csv(\"WBpanel.csv\")\n",
    "regression_data = regression_data.set_index(keys=[\"country\", \"yr\"], drop=False)\n",
    "regression_data[\"intercept\"] = 1\n",
    "\n",
    "mod = PanelOLS(\n",
    "    regression_data[\"lny\"],\n",
    "    regression_data[[\"intercept\", \"lnk\", \"lnl\", \"yr\"]],\n",
    "    entity_effects=True,\n",
    ")\n",
    "res = mod.fit(cov_type=\"clustered\", cluster_entity=True, debiased=True)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37c586d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])?  y\n"
     ]
    }
   ],
   "source": [
    "# Remove all previous function and variable definitions before the next exercise\n",
    "%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fc1016",
   "metadata": {},
   "source": [
    "## Exercise 4.3: Random Effects Regression\n",
    "\n",
    "This exercise implements a random effects panel regression model for the _WBpanel.csv_. We report cluster robust standard errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78e03aa1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        RandomEffects Estimation Summary                        \n",
      "================================================================================\n",
      "Dep. Variable:                    lny   R-squared:                        0.8926\n",
      "Estimator:              RandomEffects   R-squared (Between):              0.9125\n",
      "No. Observations:                2296   R-squared (Within):               0.8902\n",
      "Date:                Mon, Mar 13 2023   R-squared (Overall):              0.9117\n",
      "Time:                        14:26:23   Log-likelihood                    1452.3\n",
      "Cov. Estimator:             Clustered                                           \n",
      "                                        F-statistic:                      6351.5\n",
      "Entities:                          82   P-value                           0.0000\n",
      "Avg Obs:                       28.000   Distribution:                  F(3,2292)\n",
      "Min Obs:                       28.000                                           \n",
      "Max Obs:                       28.000   F-statistic (robust):             424.86\n",
      "                                        P-value                           0.0000\n",
      "Time periods:                      28   Distribution:                  F(3,2292)\n",
      "Avg Obs:                       82.000                                           \n",
      "Min Obs:                       82.000                                           \n",
      "Max Obs:                       82.000                                           \n",
      "                                                                                \n",
      "                             Parameter Estimates                              \n",
      "==============================================================================\n",
      "            Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
      "------------------------------------------------------------------------------\n",
      "intercept      0.1170     0.1304     0.8970     0.3698     -0.1388      0.3728\n",
      "lnk            0.6069     0.0436     13.905     0.0000      0.5213      0.6925\n",
      "lnl            0.2515     0.0581     4.3314     0.0000      0.1376      0.3654\n",
      "yr             0.0006     0.0023     0.2458     0.8059     -0.0040      0.0051\n",
      "==============================================================================\n",
      "Effects                   0.112335\n",
      "Residual                  0.015157\n",
      "Percent due to Effects    0.881115\n",
      "Name: Variance Decomposition, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from linearmodels import RandomEffects\n",
    "from scipy import stats\n",
    "\n",
    "regression_data = pd.read_csv(\"WBpanel.csv\")\n",
    "regression_data = regression_data.set_index(keys=[\"country\", \"yr\"], drop=False)\n",
    "regression_data[\"intercept\"] = 1\n",
    "\n",
    "re_model = RandomEffects(\n",
    "    regression_data[\"lny\"], regression_data[[\"intercept\", \"lnk\", \"lnl\", \"yr\"]]\n",
    ")\n",
    "results = re_model.fit(cov_type=\"clustered\", cluster_entity=True, debiased=True)\n",
    "print(results)\n",
    "print(results.variance_decomposition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89e166d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])?  y\n"
     ]
    }
   ],
   "source": [
    "# Remove all previous function and variable definitions before the next exercise\n",
    "%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85036f3",
   "metadata": {},
   "source": [
    "## Exercise 4.4: CSS Model Estimation \n",
    "\n",
    "This exercise estimates the stochastic frontier model with time-varying inefficiency of Cornwell, Schmidt and Sickles (1990) via the Least Squared Dummy Variable (LSDV) approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a14cfb7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "322f6384",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x00000212AEBCAD60>\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    lny   R-squared:                       0.998\n",
      "Model:                            OLS   Adj. R-squared:                  0.998\n",
      "Method:                 Least Squares   F-statistic:                     7999.\n",
      "Date:                Mon, 13 Mar 2023   Prob (F-statistic):               0.00\n",
      "Time:                        14:59:46   Log-Likelihood:                 2618.2\n",
      "No. Observations:                2296   AIC:                            -4906.\n",
      "Df Residuals:                    2131   BIC:                            -3959.\n",
      "Df Model:                         164                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=========================================================================================\n",
      "                            coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "intercept                 1.0822      0.145      7.466      0.000       0.798       1.366\n",
      "lnk                       0.5983      0.018     32.510      0.000       0.562       0.634\n",
      "lnl                       0.0944      0.061      1.537      0.125      -0.026       0.215\n",
      "cntrydum_algeria         -0.8270      0.054    -15.384      0.000      -0.932      -0.722\n",
      "cntrydum_argentina       -0.1227      0.052     -2.371      0.018      -0.224      -0.021\n",
      "cntrydum_austria         -0.0832      0.053     -1.573      0.116      -0.187       0.021\n",
      "cntrydum_bangladesh      -0.9975      0.113     -8.866      0.000      -1.218      -0.777\n",
      "cntrydum_belgium         -0.1146      0.042     -2.699      0.007      -0.198      -0.031\n",
      "cntrydum_bolivia         -1.4566      0.108    -13.445      0.000      -1.669      -1.244\n",
      "cntrydum_brazil          -0.2562      0.107     -2.399      0.017      -0.466      -0.047\n",
      "cntrydum_cameroon        -0.7823      0.103     -7.591      0.000      -0.984      -0.580\n",
      "cntrydum_canada           0.1854      0.038      4.833      0.000       0.110       0.261\n",
      "cntrydum_chile           -0.8604      0.067    -12.888      0.000      -0.991      -0.730\n",
      "cntrydum_china           -0.9796      0.239     -4.093      0.000      -1.449      -0.510\n",
      "cntrydum_colombia        -0.8670      0.062    -14.038      0.000      -0.988      -0.746\n",
      "cntrydum_costa rica      -1.1206      0.167     -6.704      0.000      -1.448      -0.793\n",
      "cntrydum_cote d'ivoir    -0.9441      0.113     -8.347      0.000      -1.166      -0.722\n",
      "cntrydum_cyprus          -1.8042      0.197     -9.151      0.000      -2.191      -1.418\n",
      "cntrydum_denmark         -0.0120      0.071     -0.170      0.865      -0.151       0.127\n",
      "cntrydum_ecuador         -1.5541      0.099    -15.672      0.000      -1.749      -1.360\n",
      "cntrydum_egypt           -0.6610      0.096     -6.897      0.000      -0.849      -0.473\n",
      "cntrydum_el salvador     -0.7825      0.128     -6.105      0.000      -1.034      -0.531\n",
      "cntrydum_ethiopia        -0.6929      0.115     -6.049      0.000      -0.918      -0.468\n",
      "cntrydum_finland         -0.4464      0.073     -6.108      0.000      -0.590      -0.303\n",
      "cntrydum_france           0.5969      0.081      7.398      0.000       0.439       0.755\n",
      "cntrydum_germany          0.5796      0.090      6.417      0.000       0.402       0.757\n",
      "cntrydum_ghana           -0.9426      0.088    -10.691      0.000      -1.115      -0.770\n",
      "cntrydum_greece          -0.5257      0.061     -8.677      0.000      -0.644      -0.407\n",
      "cntrydum_guatamala       -1.0904      0.108    -10.073      0.000      -1.303      -0.878\n",
      "cntrydum_haiti           -0.8120      0.125     -6.472      0.000      -1.058      -0.566\n",
      "cntrydum_honduras        -1.2707      0.144     -8.817      0.000      -1.553      -0.988\n",
      "cntrydum_iceland         -1.2606      0.262     -4.804      0.000      -1.775      -0.746\n",
      "cntrydum_india           -0.2132      0.213     -1.000      0.317      -0.631       0.205\n",
      "cntrydum_indonesia       -0.3087      0.145     -2.123      0.034      -0.594      -0.024\n",
      "cntrydum_iran             0.5936      0.063      9.375      0.000       0.469       0.718\n",
      "cntrydum_iraq             0.4977      0.078      6.417      0.000       0.346       0.650\n",
      "cntrydum_ireland         -0.5610      0.108     -5.184      0.000      -0.773      -0.349\n",
      "cntrydum_israel          -0.8595      0.116     -7.380      0.000      -1.088      -0.631\n",
      "cntrydum_italy            0.2893      0.088      3.285      0.001       0.117       0.462\n",
      "cntrydum_jamaica         -1.5468      0.146    -10.627      0.000      -1.832      -1.261\n",
      "cntrydum_japan            0.9007      0.126      7.177      0.000       0.655       1.147\n",
      "cntrydum_jordan          -0.8722      0.153     -5.709      0.000      -1.172      -0.573\n",
      "cntrydum_kenya           -2.1457      0.077    -27.689      0.000      -2.298      -1.994\n",
      "cntrydum_korea           -0.1300      0.092     -1.412      0.158      -0.311       0.051\n",
      "cntrydum_madagascar      -1.0681      0.103    -10.325      0.000      -1.271      -0.865\n",
      "cntrydum_malawi          -1.7015      0.138    -12.333      0.000      -1.972      -1.431\n",
      "cntrydum_malaysia        -0.5980      0.085     -7.059      0.000      -0.764      -0.432\n",
      "cntrydum_mali            -1.8251      0.111    -16.405      0.000      -2.043      -1.607\n",
      "cntrydum_mauritius       -2.1201      0.196    -10.799      0.000      -2.505      -1.735\n",
      "cntrydum_mexico          -0.2121      0.077     -2.771      0.006      -0.362      -0.062\n",
      "cntrydum_morocco         -0.8885      0.077    -11.510      0.000      -1.040      -0.737\n",
      "cntrydum_mozambique      -1.5586      0.094    -16.627      0.000      -1.742      -1.375\n",
      "cntrydum_myanmar         -1.1300      0.090    -12.509      0.000      -1.307      -0.953\n",
      "cntrydum_netherlands      0.0151      0.037      0.411      0.681      -0.057       0.087\n",
      "cntrydum_new zealand     -0.4821      0.111     -4.345      0.000      -0.700      -0.264\n",
      "cntrydum_nigeria         -0.3550      0.111     -3.210      0.001      -0.572      -0.138\n",
      "cntrydum_norway          -0.6310      0.085     -7.462      0.000      -0.797      -0.465\n",
      "cntrydum_pakistan        -0.8620      0.108     -7.962      0.000      -1.074      -0.650\n",
      "cntrydum_panama          -1.1381      0.169     -6.733      0.000      -1.470      -0.807\n",
      "cntrydum_paraguay        -1.2202      0.158     -7.726      0.000      -1.530      -0.910\n",
      "cntrydum_peru            -0.8454      0.061    -13.936      0.000      -0.964      -0.726\n",
      "cntrydum_philippines     -0.5339      0.082     -6.492      0.000      -0.695      -0.373\n",
      "cntrydum_portugal        -0.7992      0.059    -13.485      0.000      -0.915      -0.683\n",
      "cntrydum_rwanda          -0.9509      0.147     -6.490      0.000      -1.238      -0.664\n",
      "cntrydum_senegal         -1.1770      0.110    -10.654      0.000      -1.394      -0.960\n",
      "cntrydum_sierra leone    -1.8211      0.150    -12.170      0.000      -2.114      -1.528\n",
      "cntrydum_singapore       -0.6369      0.150     -4.243      0.000      -0.931      -0.343\n",
      "cntrydum_spain            0.2257      0.067      3.366      0.001       0.094       0.357\n",
      "cntrydum_sri lanka       -1.1863      0.095    -12.530      0.000      -1.372      -1.001\n",
      "cntrydum_sudan           -0.0276      0.087     -0.319      0.750      -0.198       0.142\n",
      "cntrydum_sweden           0.0533      0.046      1.150      0.250      -0.038       0.144\n",
      "cntrydum_switzerland      0.2416      0.060      4.030      0.000       0.124       0.359\n",
      "cntrydum_tanzania        -1.7139      0.090    -19.002      0.000      -1.891      -1.537\n",
      "cntrydum_thailand        -0.5939      0.090     -6.628      0.000      -0.770      -0.418\n",
      "cntrydum_tunisia         -1.4549      0.105    -13.863      0.000      -1.661      -1.249\n",
      "cntrydum_turkey          -0.6384      0.073     -8.705      0.000      -0.782      -0.495\n",
      "cntrydum_uganda          -0.3710      0.088     -4.239      0.000      -0.543      -0.199\n",
      "cntrydum_uk               0.5916      0.091      6.525      0.000       0.414       0.769\n",
      "cntrydum_uruguay         -1.1736      0.106    -11.032      0.000      -1.382      -0.965\n",
      "cntrydum_us               0.9525      0.153      6.213      0.000       0.652       1.253\n",
      "cntrydum_venezuala       -0.4419      0.064     -6.954      0.000      -0.567      -0.317\n",
      "cntrydum_zaire           -0.7014      0.087     -8.102      0.000      -0.871      -0.532\n",
      "cntrydum_zambia          -2.1445      0.112    -19.208      0.000      -2.363      -1.926\n",
      "cntrydum_zimbabwe        -1.7038      0.109    -15.643      0.000      -1.917      -1.490\n",
      "yr_algeria                0.0078      0.001      6.037      0.000       0.005       0.010\n",
      "yr_argentina             -0.0005      0.001     -0.473      0.636      -0.003       0.002\n",
      "yr_austria                0.0007      0.001      0.646      0.519      -0.001       0.003\n",
      "yr_bangladesh             0.0043      0.001      3.733      0.000       0.002       0.007\n",
      "yr_belgium                0.0046      0.001      4.631      0.000       0.003       0.007\n",
      "yr_bolivia                0.0010      0.001      0.811      0.417      -0.001       0.003\n",
      "yr_brazil                 0.0083      0.001      6.185      0.000       0.006       0.011\n",
      "yr_cameroon               0.0027      0.001      2.154      0.031       0.000       0.005\n",
      "yr_canada                 0.0069      0.001      6.055      0.000       0.005       0.009\n",
      "yr_chile                  0.0032      0.001      2.722      0.007       0.001       0.005\n",
      "yr_china                  0.0150      0.001     12.156      0.000       0.013       0.017\n",
      "yr_colombia               0.0092      0.001      7.008      0.000       0.007       0.012\n",
      "yr_costa rica             0.0023      0.001      1.579      0.115      -0.001       0.005\n",
      "yr_cote d'ivoir           0.0030      0.002      1.959      0.050   -3.32e-06       0.006\n",
      "yr_cyprus                 0.0112      0.001     10.567      0.000       0.009       0.013\n",
      "yr_denmark               -0.0006      0.001     -0.553      0.580      -0.003       0.001\n",
      "yr_ecuador                0.0128      0.001      9.396      0.000       0.010       0.015\n",
      "yr_egypt                  0.0070      0.001      5.359      0.000       0.004       0.010\n",
      "yr_el salvador           -0.0038      0.001     -3.151      0.002      -0.006      -0.001\n",
      "yr_ethiopia              -0.0024      0.001     -1.915      0.056      -0.005    5.71e-05\n",
      "yr_finland                0.0052      0.001      5.150      0.000       0.003       0.007\n",
      "yr_france                 0.0011      0.001      0.991      0.322      -0.001       0.003\n",
      "yr_germany                0.0018      0.001      1.745      0.081      -0.000       0.004\n",
      "yr_ghana                 -0.0043      0.001     -3.721      0.000      -0.007      -0.002\n",
      "yr_greece                 0.0034      0.001      3.034      0.002       0.001       0.006\n",
      "yr_guatamala              0.0047      0.001      3.689      0.000       0.002       0.007\n",
      "yr_haiti                 -0.0070      0.001     -6.185      0.000      -0.009      -0.005\n",
      "yr_honduras               0.0043      0.001      3.246      0.001       0.002       0.007\n",
      "yr_iceland                0.0080      0.001      7.173      0.000       0.006       0.010\n",
      "yr_india                  0.0031      0.001      2.626      0.009       0.001       0.005\n",
      "yr_indonesia              0.0029      0.001      2.252      0.024       0.000       0.005\n",
      "yr_iran                  -0.0088      0.002     -5.705      0.000      -0.012      -0.006\n",
      "yr_iraq                  -0.0105      0.001     -7.290      0.000      -0.013      -0.008\n",
      "yr_ireland                0.0030      0.001      2.793      0.005       0.001       0.005\n",
      "yr_israel                 0.0107      0.001      8.557      0.000       0.008       0.013\n",
      "yr_italy                  0.0053      0.001      5.145      0.000       0.003       0.007\n",
      "yr_jamaica               -0.0029      0.001     -2.656      0.008      -0.005      -0.001\n",
      "yr_japan                  0.0003      0.001      0.220      0.826      -0.002       0.003\n",
      "yr_jordan                -0.0019      0.001     -1.388      0.165      -0.004       0.001\n",
      "yr_kenya                  0.0175      0.001     12.920      0.000       0.015       0.020\n",
      "yr_korea                  0.0034      0.002      2.282      0.023       0.000       0.006\n",
      "yr_madagascar            -0.0032      0.001     -2.798      0.005      -0.006      -0.001\n",
      "yr_malawi                -0.0035      0.001     -2.522      0.012      -0.006      -0.001\n",
      "yr_malaysia               0.0021      0.001      1.427      0.154      -0.001       0.005\n",
      "yr_mali                   0.0069      0.001      6.344      0.000       0.005       0.009\n",
      "yr_mauritius              0.0109      0.001      8.839      0.000       0.008       0.013\n",
      "yr_mexico                 0.0041      0.001      2.893      0.004       0.001       0.007\n",
      "yr_morocco                0.0034      0.001      2.597      0.009       0.001       0.006\n",
      "yr_mozambique            -0.0093      0.001     -8.055      0.000      -0.012      -0.007\n",
      "yr_myanmar                0.0074      0.001      6.289      0.000       0.005       0.010\n",
      "yr_netherlands            0.0025      0.001      2.312      0.021       0.000       0.005\n",
      "yr_new zealand            0.0012      0.001      1.136      0.256      -0.001       0.003\n",
      "yr_nigeria               -0.0129      0.001     -9.678      0.000      -0.016      -0.010\n",
      "yr_norway                 0.0073      0.001      7.194      0.000       0.005       0.009\n",
      "yr_pakistan               0.0060      0.001      4.403      0.000       0.003       0.009\n",
      "yr_panama                 0.0021      0.001      1.557      0.120      -0.001       0.005\n",
      "yr_paraguay               0.0018      0.001      1.206      0.228      -0.001       0.005\n",
      "yr_peru                   0.0038      0.001      2.957      0.003       0.001       0.006\n",
      "yr_philippines            0.0002      0.001      0.160      0.873      -0.002       0.003\n",
      "yr_portugal               0.0047      0.001      4.338      0.000       0.003       0.007\n",
      "yr_rwanda                 0.0018      0.001      1.396      0.163      -0.001       0.004\n",
      "yr_senegal                0.0026      0.001      2.299      0.022       0.000       0.005\n",
      "yr_sierra leone          -0.0002      0.001     -0.167      0.867      -0.002       0.002\n",
      "yr_singapore             -0.0017      0.002     -1.035      0.301      -0.005       0.002\n",
      "yr_spain                  0.0005      0.001      0.414      0.679      -0.002       0.003\n",
      "yr_sri lanka              0.0034      0.001      2.753      0.006       0.001       0.006\n",
      "yr_sudan                 -0.0084      0.001     -6.497      0.000      -0.011      -0.006\n",
      "yr_sweden                 0.0017      0.001      1.657      0.098      -0.000       0.004\n",
      "yr_switzerland           -0.0028      0.001     -2.735      0.006      -0.005      -0.001\n",
      "yr_tanzania               0.0037      0.001      2.857      0.004       0.001       0.006\n",
      "yr_thailand               0.0028      0.001      1.856      0.064      -0.000       0.006\n",
      "yr_tunisia                0.0084      0.001      6.613      0.000       0.006       0.011\n",
      "yr_turkey                 0.0055      0.001      4.305      0.000       0.003       0.008\n",
      "yr_uganda                -0.0186      0.001    -15.046      0.000      -0.021      -0.016\n",
      "yr_uk                    -0.0006      0.001     -0.601      0.548      -0.003       0.001\n",
      "yr_uruguay                0.0026      0.001      2.738      0.006       0.001       0.004\n",
      "yr_us                     0.0046      0.001      4.321      0.000       0.002       0.007\n",
      "yr_venezuala             -0.0010      0.001     -0.712      0.476      -0.004       0.002\n",
      "yr_zaire                 -0.0011      0.001     -0.918      0.359      -0.004       0.001\n",
      "yr_zambia                 0.0022      0.001      1.773      0.076      -0.000       0.005\n",
      "yr_zimbabwe               0.0090      0.001      6.588      0.000       0.006       0.012\n",
      "yr2_algeria               0.0078      0.001      6.037      0.000       0.005       0.010\n",
      "yr2_argentina            -0.0005      0.001     -0.473      0.636      -0.003       0.002\n",
      "yr2_austria               0.0007      0.001      0.646      0.519      -0.001       0.003\n",
      "yr2_bangladesh            0.0043      0.001      3.733      0.000       0.002       0.007\n",
      "yr2_belgium               0.0046      0.001      4.631      0.000       0.003       0.007\n",
      "yr2_bolivia               0.0010      0.001      0.811      0.417      -0.001       0.003\n",
      "yr2_brazil                0.0083      0.001      6.185      0.000       0.006       0.011\n",
      "yr2_cameroon              0.0027      0.001      2.154      0.031       0.000       0.005\n",
      "yr2_canada                0.0069      0.001      6.055      0.000       0.005       0.009\n",
      "yr2_chile                 0.0032      0.001      2.722      0.007       0.001       0.005\n",
      "yr2_china                 0.0150      0.001     12.156      0.000       0.013       0.017\n",
      "yr2_colombia              0.0092      0.001      7.008      0.000       0.007       0.012\n",
      "yr2_costa rica            0.0023      0.001      1.579      0.115      -0.001       0.005\n",
      "yr2_cote d'ivoir          0.0030      0.002      1.959      0.050   -3.32e-06       0.006\n",
      "yr2_cyprus                0.0112      0.001     10.567      0.000       0.009       0.013\n",
      "yr2_denmark              -0.0006      0.001     -0.553      0.580      -0.003       0.001\n",
      "yr2_ecuador               0.0128      0.001      9.396      0.000       0.010       0.015\n",
      "yr2_egypt                 0.0070      0.001      5.359      0.000       0.004       0.010\n",
      "yr2_el salvador          -0.0038      0.001     -3.151      0.002      -0.006      -0.001\n",
      "yr2_ethiopia             -0.0024      0.001     -1.915      0.056      -0.005    5.71e-05\n",
      "yr2_finland               0.0052      0.001      5.150      0.000       0.003       0.007\n",
      "yr2_france                0.0011      0.001      0.991      0.322      -0.001       0.003\n",
      "yr2_germany               0.0018      0.001      1.745      0.081      -0.000       0.004\n",
      "yr2_ghana                -0.0043      0.001     -3.721      0.000      -0.007      -0.002\n",
      "yr2_greece                0.0034      0.001      3.034      0.002       0.001       0.006\n",
      "yr2_guatamala             0.0047      0.001      3.689      0.000       0.002       0.007\n",
      "yr2_haiti                -0.0070      0.001     -6.185      0.000      -0.009      -0.005\n",
      "yr2_honduras              0.0043      0.001      3.246      0.001       0.002       0.007\n",
      "yr2_iceland               0.0080      0.001      7.173      0.000       0.006       0.010\n",
      "yr2_india                 0.0031      0.001      2.626      0.009       0.001       0.005\n",
      "yr2_indonesia             0.0029      0.001      2.252      0.024       0.000       0.005\n",
      "yr2_iran                 -0.0088      0.002     -5.705      0.000      -0.012      -0.006\n",
      "yr2_iraq                 -0.0105      0.001     -7.290      0.000      -0.013      -0.008\n",
      "yr2_ireland               0.0030      0.001      2.793      0.005       0.001       0.005\n",
      "yr2_israel                0.0107      0.001      8.557      0.000       0.008       0.013\n",
      "yr2_italy                 0.0053      0.001      5.145      0.000       0.003       0.007\n",
      "yr2_jamaica              -0.0029      0.001     -2.656      0.008      -0.005      -0.001\n",
      "yr2_japan                 0.0003      0.001      0.220      0.826      -0.002       0.003\n",
      "yr2_jordan               -0.0019      0.001     -1.388      0.165      -0.004       0.001\n",
      "yr2_kenya                 0.0175      0.001     12.920      0.000       0.015       0.020\n",
      "yr2_korea                 0.0034      0.002      2.282      0.023       0.000       0.006\n",
      "yr2_madagascar           -0.0032      0.001     -2.798      0.005      -0.006      -0.001\n",
      "yr2_malawi               -0.0035      0.001     -2.522      0.012      -0.006      -0.001\n",
      "yr2_malaysia              0.0021      0.001      1.427      0.154      -0.001       0.005\n",
      "yr2_mali                  0.0069      0.001      6.344      0.000       0.005       0.009\n",
      "yr2_mauritius             0.0109      0.001      8.839      0.000       0.008       0.013\n",
      "yr2_mexico                0.0041      0.001      2.893      0.004       0.001       0.007\n",
      "yr2_morocco               0.0034      0.001      2.597      0.009       0.001       0.006\n",
      "yr2_mozambique           -0.0093      0.001     -8.055      0.000      -0.012      -0.007\n",
      "yr2_myanmar               0.0074      0.001      6.289      0.000       0.005       0.010\n",
      "yr2_netherlands           0.0025      0.001      2.312      0.021       0.000       0.005\n",
      "yr2_new zealand           0.0012      0.001      1.136      0.256      -0.001       0.003\n",
      "yr2_nigeria              -0.0129      0.001     -9.678      0.000      -0.016      -0.010\n",
      "yr2_norway                0.0073      0.001      7.194      0.000       0.005       0.009\n",
      "yr2_pakistan              0.0060      0.001      4.403      0.000       0.003       0.009\n",
      "yr2_panama                0.0021      0.001      1.557      0.120      -0.001       0.005\n",
      "yr2_paraguay              0.0018      0.001      1.206      0.228      -0.001       0.005\n",
      "yr2_peru                  0.0038      0.001      2.957      0.003       0.001       0.006\n",
      "yr2_philippines           0.0002      0.001      0.160      0.873      -0.002       0.003\n",
      "yr2_portugal              0.0047      0.001      4.338      0.000       0.003       0.007\n",
      "yr2_rwanda                0.0018      0.001      1.396      0.163      -0.001       0.004\n",
      "yr2_senegal               0.0026      0.001      2.299      0.022       0.000       0.005\n",
      "yr2_sierra leone         -0.0002      0.001     -0.167      0.867      -0.002       0.002\n",
      "yr2_singapore            -0.0017      0.002     -1.035      0.301      -0.005       0.002\n",
      "yr2_spain                 0.0005      0.001      0.414      0.679      -0.002       0.003\n",
      "yr2_sri lanka             0.0034      0.001      2.753      0.006       0.001       0.006\n",
      "yr2_sudan                -0.0084      0.001     -6.497      0.000      -0.011      -0.006\n",
      "yr2_sweden                0.0017      0.001      1.657      0.098      -0.000       0.004\n",
      "yr2_switzerland          -0.0028      0.001     -2.735      0.006      -0.005      -0.001\n",
      "yr2_tanzania              0.0037      0.001      2.857      0.004       0.001       0.006\n",
      "yr2_thailand              0.0028      0.001      1.856      0.064      -0.000       0.006\n",
      "yr2_tunisia               0.0084      0.001      6.613      0.000       0.006       0.011\n",
      "yr2_turkey                0.0055      0.001      4.305      0.000       0.003       0.008\n",
      "yr2_uganda               -0.0186      0.001    -15.046      0.000      -0.021      -0.016\n",
      "yr2_uk                   -0.0006      0.001     -0.601      0.548      -0.003       0.001\n",
      "yr2_uruguay               0.0026      0.001      2.738      0.006       0.001       0.004\n",
      "yr2_us                    0.0046      0.001      4.321      0.000       0.002       0.007\n",
      "yr2_venezuala            -0.0010      0.001     -0.712      0.476      -0.004       0.002\n",
      "yr2_zaire                -0.0011      0.001     -0.918      0.359      -0.004       0.001\n",
      "yr2_zambia                0.0022      0.001      1.773      0.076      -0.000       0.005\n",
      "yr2_zimbabwe              0.0090      0.001      6.588      0.000       0.006       0.012\n",
      "==============================================================================\n",
      "Omnibus:                      335.765   Durbin-Watson:                   0.529\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             4840.746\n",
      "Skew:                          -0.075   Prob(JB):                         0.00\n",
      "Kurtosis:                      10.112   Cond. No.                     7.26e+16\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 1.23e-29. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "regression_data = pd.read_csv(\"WBpanel.csv\")\n",
    "regression_data[\"intercept\"] = 1\n",
    "\n",
    "regression_data[\"yr2\"] = regression_data[\"yr\"] ** 2\n",
    "country_dummies = pd.get_dummies(\n",
    "    regression_data[\"country\"], prefix=\"cntrydum\", drop_first=True\n",
    ")\n",
    "regression_data = pd.concat([regression_data, country_dummies], axis=1)\n",
    "\n",
    "yr_df = pd.DataFrame(\n",
    "    columns=[\"yr_{}\".format(i) for i in regression_data[\"country\"].unique()[1:]]\n",
    ")\n",
    "yr2_df = pd.DataFrame(\n",
    "    columns=[\"yr2_{}\".format(i) for i in regression_data[\"country\"].unique()[1:]]\n",
    ")\n",
    "for i in regression_data[\"country\"].unique()[1:]:\n",
    "    yr_df[\"yr_{}\".format(i)] = (\n",
    "        regression_data[\"yr\"] * regression_data[\"cntrydum_{}\".format(i)]\n",
    "    )\n",
    "    yr2_df[\"yr2_{}\".format(i)] = (\n",
    "        regression_data[\"yr\"] * regression_data[\"cntrydum_{}\".format(i)]\n",
    "    )\n",
    "regression_data = pd.concat([regression_data, yr_df, yr2_df], axis=1)\n",
    "\n",
    "y = regression_data[\"lny\"]\n",
    "X = regression_data[\n",
    "    [\"intercept\", \"lnk\", \"lnl\"]\n",
    "    + [x for x in regression_data.columns if \"cntrydum\" in x]\n",
    "    + [x for x in regression_data.columns if \"yr_\" in x]\n",
    "    + [x for x in regression_data.columns if \"yr2_\" in x]\n",
    "]\n",
    "\n",
    "model = sm.OLS(y, X)\n",
    "result = model.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a06f7f36",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])?  y\n"
     ]
    }
   ],
   "source": [
    "# Remove all previous function and variable definitions before the next exercise\n",
    "%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a79c7a",
   "metadata": {},
   "source": [
    "## Exercise 4.5: LS Model Estimation\n",
    "\n",
    "This exercise estimates the stochastic frontier model with time-varying inefficiency of Lee and Schmidt (1993) via the Least Squared Dummy Variable (LSDV) approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ae9c16e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    lny   R-squared:                       0.996\n",
      "Model:                            OLS   Adj. R-squared:                  0.996\n",
      "Method:                 Least Squares   F-statistic:                     5350.\n",
      "Date:                Mon, 13 Mar 2023   Prob (F-statistic):               0.00\n",
      "Time:                        15:00:22   Log-Likelihood:                 1671.5\n",
      "No. Observations:                2296   AIC:                            -3121.\n",
      "Df Residuals:                    2185   BIC:                            -2484.\n",
      "Df Model:                         110                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=========================================================================================\n",
      "                            coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "intercept                 1.2958      0.078     16.518      0.000       1.142       1.450\n",
      "lnk                       0.5149      0.012     42.011      0.000       0.491       0.539\n",
      "lnl                       0.1609      0.033      4.913      0.000       0.097       0.225\n",
      "cntrydum_algeria         -0.6913      0.035    -19.857      0.000      -0.760      -0.623\n",
      "cntrydum_argentina       -0.2229      0.040     -5.604      0.000      -0.301      -0.145\n",
      "cntrydum_austria         -0.0755      0.037     -2.053      0.040      -0.148      -0.003\n",
      "cntrydum_bangladesh      -1.2143      0.076    -16.061      0.000      -1.363      -1.066\n",
      "cntrydum_belgium          0.0046      0.033      0.138      0.891      -0.061       0.070\n",
      "cntrydum_bolivia         -1.6379      0.058    -28.093      0.000      -1.752      -1.524\n",
      "cntrydum_brazil          -0.1534      0.071     -2.154      0.031      -0.293      -0.014\n",
      "cntrydum_cameroon        -0.9801      0.057    -17.182      0.000      -1.092      -0.868\n",
      "cntrydum_canada           0.3789      0.036     10.585      0.000       0.309       0.449\n",
      "cntrydum_chile           -0.9467      0.043    -21.986      0.000      -1.031      -0.862\n",
      "cntrydum_china           -0.8476      0.139     -6.093      0.000      -1.120      -0.575\n",
      "cntrydum_colombia        -0.8074      0.045    -17.756      0.000      -0.897      -0.718\n",
      "cntrydum_costa rica      -1.2801      0.081    -15.731      0.000      -1.440      -1.121\n",
      "cntrydum_cote d'ivoir    -1.0915      0.056    -19.489      0.000      -1.201      -0.982\n",
      "cntrydum_cyprus          -1.6283      0.105    -15.541      0.000      -1.834      -1.423\n",
      "cntrydum_denmark         -0.0286      0.044     -0.651      0.515      -0.115       0.058\n",
      "cntrydum_ecuador         -1.3823      0.052    -26.773      0.000      -1.484      -1.281\n",
      "cntrydum_egypt           -0.7620      0.061    -12.510      0.000      -0.881      -0.643\n",
      "cntrydum_el salvador     -1.1519      0.068    -16.925      0.000      -1.285      -1.018\n",
      "cntrydum_ethiopia        -1.2025      0.075    -15.973      0.000      -1.350      -1.055\n",
      "cntrydum_finland         -0.2907      0.045     -6.505      0.000      -0.378      -0.203\n",
      "cntrydum_france           0.6467      0.053     12.141      0.000       0.542       0.751\n",
      "cntrydum_germany          0.6721      0.060     11.245      0.000       0.555       0.789\n",
      "cntrydum_ghana           -1.3528      0.055    -24.395      0.000      -1.462      -1.244\n",
      "cntrydum_greece          -0.5470      0.038    -14.303      0.000      -0.622      -0.472\n",
      "cntrydum_guatamala       -1.1986      0.058    -20.544      0.000      -1.313      -1.084\n",
      "cntrydum_haiti           -1.3816      0.073    -19.005      0.000      -1.524      -1.239\n",
      "cntrydum_honduras        -1.4039      0.074    -19.077      0.000      -1.548      -1.260\n",
      "cntrydum_iceland         -1.0848      0.135     -8.008      0.000      -1.350      -0.819\n",
      "cntrydum_india           -0.3807      0.126     -3.032      0.002      -0.627      -0.135\n",
      "cntrydum_indonesia       -0.5458      0.088     -6.233      0.000      -0.718      -0.374\n",
      "cntrydum_iran             0.2011      0.043      4.672      0.000       0.117       0.286\n",
      "cntrydum_iraq             0.0548      0.040      1.359      0.174      -0.024       0.134\n",
      "cntrydum_ireland         -0.5572      0.059     -9.456      0.000      -0.673      -0.442\n",
      "cntrydum_israel          -0.6169      0.057    -10.731      0.000      -0.730      -0.504\n",
      "cntrydum_italy            0.4504      0.055      8.126      0.000       0.342       0.559\n",
      "cntrydum_jamaica         -1.7758      0.077    -23.177      0.000      -1.926      -1.626\n",
      "cntrydum_japan            0.9255      0.075     12.313      0.000       0.778       1.073\n",
      "cntrydum_jordan          -1.1820      0.079    -14.980      0.000      -1.337      -1.027\n",
      "cntrydum_kenya           -1.8759      0.048    -38.885      0.000      -1.970      -1.781\n",
      "cntrydum_korea           -0.2502      0.052     -4.837      0.000      -0.352      -0.149\n",
      "cntrydum_madagascar      -1.5019      0.064    -23.486      0.000      -1.627      -1.376\n",
      "cntrydum_malawi          -2.1826      0.074    -29.308      0.000      -2.329      -2.037\n",
      "cntrydum_malaysia        -0.7484      0.045    -16.454      0.000      -0.838      -0.659\n",
      "cntrydum_mali            -1.9573      0.067    -29.225      0.000      -2.089      -1.826\n",
      "cntrydum_mauritius       -2.0097      0.100    -20.159      0.000      -2.205      -1.814\n",
      "cntrydum_mexico          -0.2480      0.056     -4.462      0.000      -0.357      -0.139\n",
      "cntrydum_morocco         -1.0342      0.048    -21.525      0.000      -1.128      -0.940\n",
      "cntrydum_mozambique      -2.1575      0.059    -36.324      0.000      -2.274      -2.041\n",
      "cntrydum_myanmar         -1.2569      0.063    -20.018      0.000      -1.380      -1.134\n",
      "cntrydum_netherlands      0.0963      0.032      3.003      0.003       0.033       0.159\n",
      "cntrydum_new zealand     -0.4834      0.058     -8.271      0.000      -0.598      -0.369\n",
      "cntrydum_nigeria         -0.9962      0.068    -14.579      0.000      -1.130      -0.862\n",
      "cntrydum_norway          -0.3984      0.050     -7.971      0.000      -0.496      -0.300\n",
      "cntrydum_pakistan        -1.0048      0.072    -13.962      0.000      -1.146      -0.864\n",
      "cntrydum_panama          -1.2794      0.083    -15.389      0.000      -1.442      -1.116\n",
      "cntrydum_paraguay        -1.4493      0.078    -18.620      0.000      -1.602      -1.297\n",
      "cntrydum_peru            -0.9027      0.040    -22.303      0.000      -0.982      -0.823\n",
      "cntrydum_philippines     -0.7771      0.057    -13.654      0.000      -0.889      -0.666\n",
      "cntrydum_portugal        -0.7885      0.038    -20.496      0.000      -0.864      -0.713\n",
      "cntrydum_rwanda          -1.3095      0.081    -16.090      0.000      -1.469      -1.150\n",
      "cntrydum_senegal         -1.3665      0.063    -21.706      0.000      -1.490      -1.243\n",
      "cntrydum_sierra leone    -2.2342      0.086    -25.912      0.000      -2.403      -2.065\n",
      "cntrydum_singapore       -0.8430      0.070    -12.071      0.000      -0.980      -0.706\n",
      "cntrydum_spain            0.1821      0.045      4.065      0.000       0.094       0.270\n",
      "cntrydum_sri lanka       -1.4234      0.059    -24.192      0.000      -1.539      -1.308\n",
      "cntrydum_sudan           -0.5627      0.053    -10.522      0.000      -0.668      -0.458\n",
      "cntrydum_sweden           0.1107      0.035      3.138      0.002       0.042       0.180\n",
      "cntrydum_switzerland      0.1979      0.040      5.002      0.000       0.120       0.275\n",
      "cntrydum_tanzania        -1.9387      0.058    -33.230      0.000      -2.053      -1.824\n",
      "cntrydum_thailand        -0.7739      0.057    -13.505      0.000      -0.886      -0.662\n",
      "cntrydum_tunisia         -1.4176      0.055    -25.675      0.000      -1.526      -1.309\n",
      "cntrydum_turkey          -0.6720      0.052    -12.974      0.000      -0.774      -0.570\n",
      "cntrydum_uganda          -1.1946      0.055    -21.795      0.000      -1.302      -1.087\n",
      "cntrydum_uk               0.5680      0.055     10.250      0.000       0.459       0.677\n",
      "cntrydum_uruguay         -1.2512      0.063    -19.929      0.000      -1.374      -1.128\n",
      "cntrydum_us               1.1515      0.093     12.355      0.000       0.969       1.334\n",
      "cntrydum_venezuala       -0.5627      0.036    -15.747      0.000      -0.633      -0.493\n",
      "cntrydum_zaire           -1.0831      0.061    -17.694      0.000      -1.203      -0.963\n",
      "cntrydum_zambia          -2.2912      0.060    -38.259      0.000      -2.409      -2.174\n",
      "cntrydum_zimbabwe        -1.6633      0.057    -29.181      0.000      -1.775      -1.552\n",
      "yrdum_2                   0.0012      0.019      0.065      0.948      -0.035       0.038\n",
      "yrdum_3                   0.0146      0.019      0.776      0.438      -0.022       0.051\n",
      "yrdum_4                   0.0385      0.019      2.041      0.041       0.002       0.076\n",
      "yrdum_5                   0.0561      0.019      2.955      0.003       0.019       0.093\n",
      "yrdum_6                   0.0725      0.019      3.785      0.000       0.035       0.110\n",
      "yrdum_7                   0.0828      0.019      4.283      0.000       0.045       0.121\n",
      "yrdum_8                   0.0826      0.020      4.218      0.000       0.044       0.121\n",
      "yrdum_9                   0.1017      0.020      5.127      0.000       0.063       0.141\n",
      "yrdum_10                  0.1282      0.020      6.366      0.000       0.089       0.168\n",
      "yrdum_11                  0.1491      0.020      7.284      0.000       0.109       0.189\n",
      "yrdum_12                  0.1599      0.021      7.665      0.000       0.119       0.201\n",
      "yrdum_13                  0.1764      0.021      8.289      0.000       0.135       0.218\n",
      "yrdum_14                  0.1890      0.022      8.704      0.000       0.146       0.232\n",
      "yrdum_15                  0.1920      0.022      8.659      0.000       0.149       0.236\n",
      "yrdum_16                  0.1772      0.023      7.822      0.000       0.133       0.222\n",
      "yrdum_17                  0.1937      0.023      8.351      0.000       0.148       0.239\n",
      "yrdum_18                  0.2014      0.024      8.483      0.000       0.155       0.248\n",
      "yrdum_19                  0.2056      0.024      8.461      0.000       0.158       0.253\n",
      "yrdum_20                  0.2212      0.025      8.896      0.000       0.172       0.270\n",
      "yrdum_21                  0.2133      0.025      8.393      0.000       0.163       0.263\n",
      "yrdum_22                  0.2021      0.026      7.777      0.000       0.151       0.253\n",
      "yrdum_23                  0.1876      0.027      7.075      0.000       0.136       0.240\n",
      "yrdum_24                  0.1822      0.027      6.744      0.000       0.129       0.235\n",
      "yrdum_25                  0.1891      0.027      6.880      0.000       0.135       0.243\n",
      "yrdum_26                  0.1928      0.028      6.868      0.000       0.138       0.248\n",
      "yrdum_27                  0.2034      0.029      7.113      0.000       0.147       0.260\n",
      "yrdum_28                  0.2172      0.029      7.457      0.000       0.160       0.274\n",
      "==============================================================================\n",
      "Omnibus:                      392.679   Durbin-Watson:                   0.332\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2722.020\n",
      "Skew:                          -0.619   Prob(JB):                         0.00\n",
      "Kurtosis:                       8.188   Cond. No.                         835.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "regression_data = pd.read_csv(\"WBpanel.csv\")\n",
    "regression_data[\"intercept\"] = 1\n",
    "\n",
    "country_dummies = pd.get_dummies(\n",
    "    regression_data[\"country\"], prefix=\"cntrydum\", drop_first=True\n",
    ")\n",
    "year_dummies = pd.get_dummies(regression_data[\"yr\"], prefix=\"yrdum\", drop_first=True)\n",
    "regression_data = pd.concat([regression_data, country_dummies, year_dummies], axis=1)\n",
    "\n",
    "y = regression_data[\"lny\"]\n",
    "X = regression_data[\n",
    "    [\"intercept\", \"lnk\", \"lnl\"]\n",
    "    + [x for x in regression_data.columns if \"cntrydum\" in x]\n",
    "    + [x for x in regression_data.columns if \"yrdum\" in x]\n",
    "]\n",
    "\n",
    "model = sm.OLS(y, X)\n",
    "result = model.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d5d9b0f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])?  y\n"
     ]
    }
   ],
   "source": [
    "# Remove all previous function and variable definitions before the next exercise\n",
    "%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe93164",
   "metadata": {},
   "source": [
    "## Exercise 4.6: Random effects with Time-Invariant Inefficiency via MLE\n",
    "\n",
    "This exercise estimates a random effects stochastic frontier model with time-invariant inefficiency via MLE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0b3b19c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numdifftools as nd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "def estimate(production_data):\n",
    "    # Starting values for MLE\n",
    "    alpha = 1.3\n",
    "    beta1 = 0.6\n",
    "    beta2 = 0.2\n",
    "    sigma2u = 0.3\n",
    "    sigma2v = 0.01\n",
    "    mu = 1.1\n",
    "\n",
    "    # Initial parameter vector\n",
    "    theta0 = np.array([alpha, beta1, beta2, mu, sigma2u, sigma2v])\n",
    "    # Bounds to ensure Sigma2u and Sigma2v are positive\n",
    "    bounds = [(None, None) for x in range(len(theta0) - 2)] + [\n",
    "        (1e-3, np.inf),\n",
    "        (1e-3, np.inf),\n",
    "    ]\n",
    "\n",
    "    MLE_results = minimize(\n",
    "        loglikelihood,\n",
    "        theta0,\n",
    "        method=\"L-BFGS-B\",\n",
    "        options={\"maxiter\": 10000, \"maxfun\": 20000, \"maxcor\": 100},\n",
    "        args=(production_data),\n",
    "        bounds=bounds,\n",
    "    )\n",
    "    theta = MLE_results.x\n",
    "    logMLE = MLE_results.fun * -1\n",
    "\n",
    "    # Estimate the hessian\n",
    "    hessian = nd.Hessian(f=loglikelihood, method=\"central\", step=1e-6)(\n",
    "        theta, production_data\n",
    "    )\n",
    "\n",
    "    # Estimation of standard errors\n",
    "    ster = np.sqrt(np.diag(np.linalg.inv(hessian)))\n",
    "\n",
    "    return theta, ster, logMLE\n",
    "\n",
    "\n",
    "def loglikelihood(coefs, production_data):\n",
    "    # Obtain the log likelihood\n",
    "    logDen = log_density(coefs, production_data)\n",
    "    log_likelihood = -np.sum(logDen)\n",
    "\n",
    "    return log_likelihood\n",
    "\n",
    "\n",
    "def log_density(coefs, production_data):\n",
    "    alpha = coefs[0]\n",
    "    beta1 = coefs[1]\n",
    "    beta2 = coefs[2]\n",
    "    mu = coefs[3]\n",
    "    sigma2u = coefs[4]\n",
    "    sigma2v = coefs[5]\n",
    "\n",
    "    panels = np.unique(production_data[:, 0])\n",
    "    logDen_is = np.zeros(len(panels))\n",
    "    for j in range(len(panels)):\n",
    "        i = panels[j]\n",
    "        production_data_i = production_data[production_data[:, 0] == i, :]\n",
    "        y = production_data_i[:, 1]\n",
    "        x1 = production_data_i[:, 2]\n",
    "        x2 = production_data_i[:, 3]\n",
    "        T = len(production_data_i)\n",
    "        eps_i = y - alpha - x1 * beta1 - x2 * beta2\n",
    "\n",
    "        sigma2_star = (sigma2v * sigma2u) / (sigma2v + T * sigma2u)\n",
    "        mu_i_star = (sigma2v * mu - sigma2u * sum(eps_i)) / (sigma2v + T * sigma2u)\n",
    "        normdcdf_1 = stats.norm.cdf(mu_i_star / np.sqrt(sigma2_star))\n",
    "        if normdcdf_1 < 1e-6:\n",
    "            normdcdf_1 = 1e-6\n",
    "        logDen_i = (\n",
    "            0.5 * np.log(sigma2_star)\n",
    "            + np.log(normdcdf_1)\n",
    "            - 0.5\n",
    "            * (\n",
    "                np.sum(eps_i**2) / sigma2v\n",
    "                + (mu / np.sqrt(sigma2u)) ** 2\n",
    "                - (mu_i_star / np.sqrt(sigma2_star)) ** 2\n",
    "            )\n",
    "            - T * np.log(np.sqrt(sigma2v))\n",
    "            - np.log(np.sqrt(sigma2u))\n",
    "            - np.log(stats.norm.cdf(mu / np.sqrt(sigma2u)))\n",
    "        )\n",
    "        logDen_is[j] = logDen_i\n",
    "\n",
    "    return logDen_is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dc57cf10",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LL 3370.215\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Est</th>\n",
       "      <th>Std.Err</th>\n",
       "      <th>z</th>\n",
       "      <th>p&gt;|z|</th>\n",
       "      <th>[95%Conf.</th>\n",
       "      <th>Interv]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>$$\\beta_{0}$$</th>\n",
       "      <td>1.29718</td>\n",
       "      <td>0.08671</td>\n",
       "      <td>14.95948</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.12722</td>\n",
       "      <td>1.46713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$$\\beta_{1}$$</th>\n",
       "      <td>0.59481</td>\n",
       "      <td>0.01018</td>\n",
       "      <td>58.43036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.57486</td>\n",
       "      <td>0.61476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$$\\beta_{2}$$</th>\n",
       "      <td>0.28373</td>\n",
       "      <td>0.02643</td>\n",
       "      <td>10.73666</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.23194</td>\n",
       "      <td>0.33553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$$\\mu$$</th>\n",
       "      <td>1.14808</td>\n",
       "      <td>0.10984</td>\n",
       "      <td>10.4524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9328</td>\n",
       "      <td>1.36336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$$\\sigma^{2}_{u}$$</th>\n",
       "      <td>0.36598</td>\n",
       "      <td>0.07403</td>\n",
       "      <td>4.94364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.22089</td>\n",
       "      <td>0.51108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$$\\sigma^{2}_{v}$$</th>\n",
       "      <td>0.01559</td>\n",
       "      <td>0.00047</td>\n",
       "      <td>33.24991</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01467</td>\n",
       "      <td>0.01651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Est  Std.Err         z p>|z| [95%Conf.  Interv]\n",
       "$$\\beta_{0}$$       1.29718  0.08671  14.95948   0.0   1.12722  1.46713\n",
       "$$\\beta_{1}$$       0.59481  0.01018  58.43036   0.0   0.57486  0.61476\n",
       "$$\\beta_{2}$$       0.28373  0.02643  10.73666   0.0   0.23194  0.33553\n",
       "                                                                       \n",
       "$$\\mu$$             1.14808  0.10984   10.4524   0.0    0.9328  1.36336\n",
       "                                                                       \n",
       "$$\\sigma^{2}_{u}$$  0.36598  0.07403   4.94364   0.0   0.22089  0.51108\n",
       "$$\\sigma^{2}_{v}$$  0.01559  0.00047  33.24991   0.0   0.01467  0.01651"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "production_data = pd.read_csv(\"WBpanel.csv\")\n",
    "production_data = production_data[[\"code\", \"lny\", \"lnk\", \"lnl\"]].values\n",
    "\n",
    "# Estimate coefficients via MLE\n",
    "theta, sterr, logMLE = estimate(production_data)\n",
    "\n",
    "Zscores = theta / sterr\n",
    "Pvalues = 2 * (1 - stats.norm.cdf(np.abs(Zscores)))\n",
    "lower_ConfInt95 = stats.norm.ppf(0.025, loc=theta, scale=sterr)\n",
    "upper_ConfInt95 = stats.norm.ppf(0.975, loc=theta, scale=sterr)\n",
    "\n",
    "# Display the results as a table\n",
    "results = pd.DataFrame(\n",
    "    columns=[\"Est\", \"Std.Err\", \"z\", \"p>|z|\", \"[95%Conf.\", \"Interv]\"],\n",
    "    index=[\n",
    "        r\"$$\\beta_{0}$$\",\n",
    "        r\"$$\\beta_{1}$$\",\n",
    "        r\"$$\\beta_{2}$$\",\n",
    "        \" \",\n",
    "        r\"$$\\mu$$\",\n",
    "        \" \",\n",
    "        r\"$$\\sigma^{2}_{u}$$\",\n",
    "        r\"$$\\sigma^{2}_{v}$$\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "theta = np.round(theta.reshape(-1, 1), 5)\n",
    "sterr = np.round(sterr.reshape(-1, 1), 5)\n",
    "Zscores = np.round(Zscores.reshape(-1, 1), 5)\n",
    "Pvalues = np.round(Pvalues.reshape(-1, 1), 5)\n",
    "lower_ConfInt95 = np.round(lower_ConfInt95.reshape(-1, 1), 5)\n",
    "upper_ConfInt95 = np.round(upper_ConfInt95.reshape(-1, 1), 5)\n",
    "\n",
    "frontier = np.concatenate(\n",
    "    [\n",
    "        theta[:3],\n",
    "        sterr[:3],\n",
    "        Zscores[:3],\n",
    "        Pvalues[:3],\n",
    "        lower_ConfInt95[:3],\n",
    "        upper_ConfInt95[:3],\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "mu = np.concatenate(\n",
    "    [theta[3], sterr[3], Zscores[3], Pvalues[3], lower_ConfInt95[3], upper_ConfInt95[3]]\n",
    ").T\n",
    "sigmas = np.concatenate(\n",
    "    [\n",
    "        theta[4:],\n",
    "        sterr[4:],\n",
    "        Zscores[4:],\n",
    "        Pvalues[4:],\n",
    "        lower_ConfInt95[4:],\n",
    "        upper_ConfInt95[4:],\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "print(\"\\nLL\", round(logMLE, 3))\n",
    "results.iloc[0:3, :] = frontier\n",
    "results.iloc[3, :] = np.full(shape=(1, 6), fill_value=\" \")\n",
    "results.iloc[4, :] = mu\n",
    "results.iloc[5, :] = np.full(shape=(1, 6), fill_value=\" \")\n",
    "results.iloc[6:, :] = sigmas\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6886a9af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])?  y\n"
     ]
    }
   ],
   "source": [
    "# Remove all previous function and variable definitions before the next exercise\n",
    "%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f531ccf",
   "metadata": {},
   "source": [
    "## Exercise 4.7: BC92 “time-varying decay” model\n",
    "\n",
    "This exercise estimates the time-varying decay model of Battese and Coelli (1992) via MLE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a0cc29a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numdifftools as nd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "def estimate(production_data):\n",
    "    # Starting values for MLE\n",
    "    alpha = 6.3\n",
    "    beta1 = 0.5\n",
    "    beta2 = 0.17\n",
    "    sigma2u = 0.4\n",
    "    sigma2v = 0.015\n",
    "    mu = 5.8\n",
    "    gamma = 0.0007\n",
    "\n",
    "    # Initial parameter vector\n",
    "    theta0 = np.array([alpha, beta1, beta2, mu, gamma, sigma2u, sigma2v])\n",
    "\n",
    "    # Bounds to ensure Sigma2v and Sigma2v are positive\n",
    "    bounds = [(None, None) for x in range(len(theta0) - 2)] + [\n",
    "        (1e-3, np.inf),\n",
    "        (1e-3, np.inf),\n",
    "    ]\n",
    "\n",
    "    MLE_results = minimize(\n",
    "        loglikelihood,\n",
    "        theta0,\n",
    "        method=\"L-BFGS-B\",\n",
    "        options={\"maxiter\": 10000, \"maxfun\": 20000, \"maxcor\": 100},\n",
    "        args=(production_data),\n",
    "        bounds=bounds,\n",
    "    )\n",
    "    theta = MLE_results.x\n",
    "    logMLE = MLE_results.fun * -1\n",
    "\n",
    "    # Estimate the hessian\n",
    "    hessian = nd.Hessian(f=loglikelihood, method=\"central\", step=1e-3)(\n",
    "        theta, production_data\n",
    "    )\n",
    "\n",
    "    # Estimation of standard errors\n",
    "    ster = np.sqrt(np.diag(np.linalg.inv(hessian)))\n",
    "\n",
    "    return theta, ster, logMLE\n",
    "\n",
    "\n",
    "def loglikelihood(coefs, production_data):\n",
    "    # Obtain the log likelihood\n",
    "    logDen = log_density(coefs, production_data)\n",
    "    log_likelihood = -np.sum(logDen)\n",
    "\n",
    "    return log_likelihood\n",
    "\n",
    "\n",
    "def log_density(coefs, production_data):\n",
    "    alpha = coefs[0]\n",
    "    beta1 = coefs[1]\n",
    "    beta2 = coefs[2]\n",
    "    mu = coefs[3]\n",
    "    gamma = coefs[4]\n",
    "    sigma2u = coefs[5]\n",
    "    sigma2v = coefs[6]\n",
    "\n",
    "    panels = np.unique(production_data[:, 0])\n",
    "    logDen_is = np.zeros(len(panels))\n",
    "    for j in range(len(panels)):\n",
    "        i = panels[j]\n",
    "        production_data_i = production_data[production_data[:, 0] == i, :]\n",
    "\n",
    "        y = production_data_i[:, 2]\n",
    "        x1 = production_data_i[:, 3]\n",
    "        x2 = production_data_i[:, 4]\n",
    "\n",
    "        t = production_data_i[:, 1]\n",
    "        T = len(production_data_i)\n",
    "        G_t = np.exp(gamma * (t - T))\n",
    "\n",
    "        eps_i = y - alpha - x1 * beta1 - x2 * beta2\n",
    "        sigma2_star = (sigma2v * sigma2u) / (sigma2v + sigma2u * np.sum(G_t**2))\n",
    "        mu_i_star = (sigma2v * mu - sigma2u * np.sum(G_t * eps_i)) / (\n",
    "            sigma2v + sigma2u * np.sum(G_t**2)\n",
    "        )\n",
    "        normdcdf_1 = stats.norm.cdf(mu_i_star / np.sqrt(sigma2_star))\n",
    "        logDen_i = (\n",
    "            0.5 * np.log(sigma2_star)\n",
    "            + np.log(normdcdf_1)\n",
    "            - 0.5\n",
    "            * (\n",
    "                np.sum(eps_i**2) / sigma2v\n",
    "                + (mu / np.sqrt(sigma2u)) ** 2\n",
    "                - (mu_i_star / np.sqrt(sigma2_star)) ** 2\n",
    "            )\n",
    "            - T * np.log(np.sqrt(sigma2v))\n",
    "            - np.log(np.sqrt(sigma2u))\n",
    "            - np.log(stats.norm.cdf(mu / np.sqrt(sigma2u)))\n",
    "        )\n",
    "        logDen_is[j] = logDen_i\n",
    "\n",
    "    return logDen_is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0b1647e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LL 3382.773\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Est</th>\n",
       "      <th>Std.Err</th>\n",
       "      <th>z</th>\n",
       "      <th>p&gt;|z|</th>\n",
       "      <th>[95%Conf.</th>\n",
       "      <th>Interv]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>$$\\beta_{0}$$</th>\n",
       "      <td>6.3039</td>\n",
       "      <td>4.21108</td>\n",
       "      <td>1.49698</td>\n",
       "      <td>0.1344</td>\n",
       "      <td>-1.94966</td>\n",
       "      <td>14.55746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lnk</th>\n",
       "      <td>0.56151</td>\n",
       "      <td>0.01422</td>\n",
       "      <td>39.49617</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.53365</td>\n",
       "      <td>0.58938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lnl</th>\n",
       "      <td>0.1856</td>\n",
       "      <td>0.03198</td>\n",
       "      <td>5.80437</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12293</td>\n",
       "      <td>0.24827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$$\\mu$$</th>\n",
       "      <td>5.79624</td>\n",
       "      <td>4.18832</td>\n",
       "      <td>1.38391</td>\n",
       "      <td>0.16639</td>\n",
       "      <td>-2.41272</td>\n",
       "      <td>14.0052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$$\\gamma$$</th>\n",
       "      <td>-0.00079</td>\n",
       "      <td>0.00052</td>\n",
       "      <td>-1.50876</td>\n",
       "      <td>0.13136</td>\n",
       "      <td>-0.00181</td>\n",
       "      <td>0.00023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$$\\sigma^{2}_{u}$$</th>\n",
       "      <td>0.40463</td>\n",
       "      <td>0.06632</td>\n",
       "      <td>6.10162</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.27465</td>\n",
       "      <td>0.53461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$$\\sigma^{2}_{v}$$</th>\n",
       "      <td>0.0152</td>\n",
       "      <td>0.00045</td>\n",
       "      <td>33.5549</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01431</td>\n",
       "      <td>0.01609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Est  Std.Err         z    p>|z| [95%Conf.   Interv]\n",
       "$$\\beta_{0}$$        6.3039  4.21108   1.49698   0.1344  -1.94966  14.55746\n",
       "lnk                 0.56151  0.01422  39.49617      0.0   0.53365   0.58938\n",
       "lnl                  0.1856  0.03198   5.80437      0.0   0.12293   0.24827\n",
       "                                                                           \n",
       "$$\\mu$$             5.79624  4.18832   1.38391  0.16639  -2.41272   14.0052\n",
       "                                                                           \n",
       "$$\\gamma$$         -0.00079  0.00052  -1.50876  0.13136  -0.00181   0.00023\n",
       "$$\\sigma^{2}_{u}$$  0.40463  0.06632   6.10162      0.0   0.27465   0.53461\n",
       "$$\\sigma^{2}_{v}$$   0.0152  0.00045   33.5549      0.0   0.01431   0.01609"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "production_data = pd.read_csv(r\"WBpanel.csv\")\n",
    "production_data = production_data[[\"code\", \"yr\", \"lny\", \"lnk\", \"lnl\"]].values\n",
    "\n",
    "# Estimate coefficients via MLE\n",
    "theta, sterr, logMLE = estimate(production_data)\n",
    "\n",
    "Zscores = theta / sterr\n",
    "Pvalues = 2 * (1 - stats.norm.cdf(np.abs(Zscores)))\n",
    "lower_ConfInt95 = stats.norm.ppf(0.025, loc=theta, scale=sterr)\n",
    "upper_ConfInt95 = stats.norm.ppf(0.975, loc=theta, scale=sterr)\n",
    "\n",
    "# Display the results as a table\n",
    "results = pd.DataFrame(\n",
    "    columns=[\"Est\", \"Std.Err\", \"z\", \"p>|z|\", \"[95%Conf.\", \"Interv]\"],\n",
    "    index=[\n",
    "        r\"$$\\beta_{0}$$\",\n",
    "        r\"lnk\",\n",
    "        r\"lnl\",\n",
    "        \" \",\n",
    "        r\"$$\\mu$$\",\n",
    "        \" \",\n",
    "        r\"$$\\gamma$$\",\n",
    "        r\"$$\\sigma^{2}_{u}$$\",\n",
    "        r\"$$\\sigma^{2}_{v}$$\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "theta = np.round(theta.reshape(-1, 1), 5)\n",
    "sterr = np.round(sterr.reshape(-1, 1), 5)\n",
    "Zscores = np.round(Zscores.reshape(-1, 1), 5)\n",
    "Pvalues = np.round(Pvalues.reshape(-1, 1), 5)\n",
    "lower_ConfInt95 = np.round(lower_ConfInt95.reshape(-1, 1), 5)\n",
    "upper_ConfInt95 = np.round(upper_ConfInt95.reshape(-1, 1), 5)\n",
    "\n",
    "frontier = np.concatenate(\n",
    "    [\n",
    "        theta[:3],\n",
    "        sterr[:3],\n",
    "        Zscores[:3],\n",
    "        Pvalues[:3],\n",
    "        lower_ConfInt95[:3],\n",
    "        upper_ConfInt95[:3],\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "mu = np.concatenate(\n",
    "    [theta[3], sterr[3], Zscores[3], Pvalues[3], lower_ConfInt95[3], upper_ConfInt95[3]]\n",
    ").T\n",
    "sigmas = np.concatenate(\n",
    "    [\n",
    "        theta[4:],\n",
    "        sterr[4:],\n",
    "        Zscores[4:],\n",
    "        Pvalues[4:],\n",
    "        lower_ConfInt95[4:],\n",
    "        upper_ConfInt95[4:],\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "print(\"\\nLL\", round(logMLE, 3))\n",
    "results.iloc[0:3, :] = frontier\n",
    "results.iloc[3, :] = np.full(shape=(1, 6), fill_value=\" \")\n",
    "results.iloc[4, :] = mu\n",
    "results.iloc[5, :] = np.full(shape=(1, 6), fill_value=\" \")\n",
    "results.iloc[6:, :] = sigmas\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "44a58861",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])?  y\n"
     ]
    }
   ],
   "source": [
    "# Remove all previous function and variable definitions before the next exercise\n",
    "%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2fb604",
   "metadata": {},
   "source": [
    "## Exercise 4.8: BC95 with non-constant $\\mu$\n",
    "\n",
    "This execise exercise the model of Battese and Coelli (1995) with non-constant $\\mu$ via MLE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "12d93f4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numdifftools as nd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "def estimate(production_data):\n",
    "    # Starting values for MLE\n",
    "    alpha = 1.7  # cons\n",
    "    beta1 = 0.5  # lnk\n",
    "    beta2 = 0.3  # lnl\n",
    "    beta3 = 0.004  # yr\n",
    "    sigma2u = 0.23\n",
    "    sigma2v = 0.015\n",
    "    delta0 = 1.8\n",
    "    delta1 = -0.3\n",
    "    gamma = 0.0005\n",
    "\n",
    "    # Initial parameter vector\n",
    "    theta0 = np.array(\n",
    "        [alpha, beta1, beta2, beta3, delta0, delta1, gamma, sigma2u, sigma2v]\n",
    "    )\n",
    "\n",
    "    # Bounds to ensure Sigma2v and Sigma2v are positive\n",
    "    bounds = [(None, None) for x in range(len(theta0) - 2)] + [\n",
    "        (1e-3, np.inf),\n",
    "        (1e-3, np.inf),\n",
    "    ]\n",
    "\n",
    "    MLE_results = minimize(\n",
    "        loglikelihood,\n",
    "        theta0,\n",
    "        method=\"L-BFGS-B\",\n",
    "        options={\"maxiter\": 1000, \"maxfun\": 10000, \"maxcor\": 100},\n",
    "        args=(production_data),\n",
    "        bounds=bounds,\n",
    "    )\n",
    "    theta = MLE_results.x\n",
    "    logMLE = MLE_results.fun * -1\n",
    "\n",
    "    # Estimate the hessian\n",
    "    hessian = nd.Hessian(f=loglikelihood, method=\"central\", step=1e-3)(\n",
    "        theta, production_data\n",
    "    )\n",
    "\n",
    "    # Estimation of standard errors\n",
    "    ster = np.sqrt(np.diag(np.linalg.inv(hessian)))\n",
    "\n",
    "    return theta, ster, logMLE\n",
    "\n",
    "\n",
    "def loglikelihood(coefs, production_data):\n",
    "    # Obtain the log likelihood\n",
    "    logDen = log_density(coefs, production_data)\n",
    "    log_likelihood = -np.sum(logDen)\n",
    "\n",
    "    return log_likelihood\n",
    "\n",
    "\n",
    "def log_density(coefs, production_data):\n",
    "    alpha = coefs[0]\n",
    "    beta1 = coefs[1]\n",
    "    beta2 = coefs[2]\n",
    "    beta3 = coefs[3]\n",
    "    delta0 = coefs[4]\n",
    "    delta1 = coefs[5]\n",
    "    gamma = coefs[6]\n",
    "    sigma2u = coefs[7]\n",
    "    sigma2v = coefs[8]\n",
    "\n",
    "    panels = np.unique(production_data[:, 0])\n",
    "    logDen_is = np.zeros(len(panels))\n",
    "    for j in range(len(panels)):\n",
    "        i = panels[j]\n",
    "        production_data_i = production_data[production_data[:, 0] == i, :]\n",
    "\n",
    "        y = production_data_i[:, 2]\n",
    "        x1 = production_data_i[:, 3]  # lnk\n",
    "        x2 = production_data_i[:, 4]  # lnl\n",
    "        x3 = production_data_i[:, 1]  # yr\n",
    "\n",
    "        z1 = np.unique(production_data_i[:, 6])[0]  # iniStat\n",
    "        z2 = production_data_i[:, 5]  # yrT\n",
    "\n",
    "        T = len(production_data_i)\n",
    "        G_t = np.exp(gamma * z2)\n",
    "\n",
    "        mu = delta0 + delta1 * z1\n",
    "\n",
    "        eps_i = y - alpha - x1 * beta1 - x2 * beta2 - x3 * beta3\n",
    "        sigma2_star = (sigma2v * sigma2u) / (sigma2v + sigma2u * np.sum(G_t**2))\n",
    "        mu_i_star = (sigma2v * mu - sigma2u * np.sum(G_t * eps_i)) / (\n",
    "            sigma2v + sigma2u * np.sum(G_t**2)\n",
    "        )\n",
    "        normdcdf_1 = stats.norm.cdf(mu_i_star / np.sqrt(sigma2_star))\n",
    "        logDen_i = (\n",
    "            0.5 * np.log(sigma2_star)\n",
    "            + np.log(normdcdf_1)\n",
    "            - 0.5\n",
    "            * (\n",
    "                np.sum(eps_i**2) / sigma2v\n",
    "                + (mu / np.sqrt(sigma2u)) ** 2\n",
    "                - (mu_i_star / np.sqrt(sigma2_star)) ** 2\n",
    "            )\n",
    "            - T * np.log(np.sqrt(sigma2v))\n",
    "            - np.log(np.sqrt(sigma2u))\n",
    "            - np.log(stats.norm.cdf(mu / np.sqrt(sigma2u)))\n",
    "        )\n",
    "        logDen_is[j] = logDen_i\n",
    "\n",
    "    return logDen_is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a1846b3d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LL 3404.678\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Est</th>\n",
       "      <th>Std.Err</th>\n",
       "      <th>z</th>\n",
       "      <th>p&gt;|z|</th>\n",
       "      <th>[95%Conf.</th>\n",
       "      <th>Interv]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>$$\\beta_{0}$$</th>\n",
       "      <td>1.70086</td>\n",
       "      <td>0.17318</td>\n",
       "      <td>9.82111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.36142</td>\n",
       "      <td>2.04029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lnk</th>\n",
       "      <td>0.53548</td>\n",
       "      <td>0.01524</td>\n",
       "      <td>35.14581</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50562</td>\n",
       "      <td>0.56535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lnl</th>\n",
       "      <td>0.29916</td>\n",
       "      <td>0.03914</td>\n",
       "      <td>7.64408</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.22246</td>\n",
       "      <td>0.37587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yr</th>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.00138</td>\n",
       "      <td>3.19106</td>\n",
       "      <td>0.00142</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$$\\gamma_{0}$$</th>\n",
       "      <td>1.84402</td>\n",
       "      <td>0.13881</td>\n",
       "      <td>13.28474</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.57196</td>\n",
       "      <td>2.11608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iniStat</th>\n",
       "      <td>-0.3104</td>\n",
       "      <td>0.04262</td>\n",
       "      <td>-7.28277</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.39393</td>\n",
       "      <td>-0.22686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yrT</th>\n",
       "      <td>0.00054</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.78135</td>\n",
       "      <td>0.4346</td>\n",
       "      <td>-0.00082</td>\n",
       "      <td>0.00191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$$\\sigma^{2}_{u}$$</th>\n",
       "      <td>0.23269</td>\n",
       "      <td>0.04513</td>\n",
       "      <td>5.15607</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14424</td>\n",
       "      <td>0.32114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$$\\sigma^{2}_{v}$$</th>\n",
       "      <td>0.01532</td>\n",
       "      <td>0.00046</td>\n",
       "      <td>33.35111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01442</td>\n",
       "      <td>0.01622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Est  Std.Err         z    p>|z| [95%Conf.  Interv]\n",
       "$$\\beta_{0}$$       1.70086  0.17318   9.82111      0.0   1.36142  2.04029\n",
       "lnk                 0.53548  0.01524  35.14581      0.0   0.50562  0.56535\n",
       "lnl                 0.29916  0.03914   7.64408      0.0   0.22246  0.37587\n",
       "yr                   0.0044  0.00138   3.19106  0.00142    0.0017   0.0071\n",
       "                                                                          \n",
       "$$\\gamma_{0}$$      1.84402  0.13881  13.28474      0.0   1.57196  2.11608\n",
       "iniStat             -0.3104  0.04262  -7.28277      0.0  -0.39393 -0.22686\n",
       "                                                                          \n",
       "yrT                 0.00054   0.0007   0.78135   0.4346  -0.00082  0.00191\n",
       "                                                                          \n",
       "$$\\sigma^{2}_{u}$$  0.23269  0.04513   5.15607      0.0   0.14424  0.32114\n",
       "$$\\sigma^{2}_{v}$$  0.01532  0.00046  33.35111      0.0   0.01442  0.01622"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "production_data = pd.read_csv(r\"WBpanel.csv\")\n",
    "\n",
    "# create the yrT and iniStat variables\n",
    "production_data.sort_values(by=[\"code\", \"yr\"])\n",
    "bigT = np.max(production_data[\"yr\"])\n",
    "production_data[\"yrT\"] = production_data[\"yr\"] - bigT\n",
    "production_data[\"ic1\"] = np.where(\n",
    "    production_data[\"yr\"] == 1, production_data[\"lnk\"] - production_data[\"lnl\"], np.nan\n",
    ")\n",
    "iniStat_data = production_data.groupby([\"code\"], as_index=False)[\"ic1\"].mean()\n",
    "iniStat_data.rename(columns={\"ic1\": \"iniStat\"}, inplace=True)\n",
    "production_data = production_data.merge(iniStat_data, how=\"left\", on=[\"code\"])\n",
    "\n",
    "production_data = production_data[\n",
    "    [\"code\", \"yr\", \"lny\", \"lnk\", \"lnl\", \"yrT\", \"iniStat\"]\n",
    "].values\n",
    "\n",
    "# Estimate coefficients via MLE\n",
    "theta, sterr, logMLE = estimate(production_data)\n",
    "\n",
    "Zscores = theta / sterr\n",
    "Pvalues = 2 * (1 - stats.norm.cdf(np.abs(Zscores)))\n",
    "lower_ConfInt95 = stats.norm.ppf(0.025, loc=theta, scale=sterr)\n",
    "upper_ConfInt95 = stats.norm.ppf(0.975, loc=theta, scale=sterr)\n",
    "\n",
    "# Display the results as a table\n",
    "results = pd.DataFrame(\n",
    "    columns=[\"Est\", \"Std.Err\", \"z\", \"p>|z|\", \"[95%Conf.\", \"Interv]\"],\n",
    "    index=[\n",
    "        r\"$$\\beta_{0}$$\",\n",
    "        \"lnk\",\n",
    "        \"lnl\",\n",
    "        \"yr\",\n",
    "        \" \",\n",
    "        \"$$\\gamma_{0}$$\",\n",
    "        \"iniStat\",\n",
    "        \" \",\n",
    "        \"yrT\",\n",
    "        \" \",\n",
    "        r\"$$\\sigma^{2}_{u}$$\",\n",
    "        r\"$$\\sigma^{2}_{v}$$\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "theta = np.round(theta.reshape(-1, 1), 5)\n",
    "sterr = np.round(sterr.reshape(-1, 1), 5)\n",
    "Zscores = np.round(Zscores.reshape(-1, 1), 5)\n",
    "Pvalues = np.round(Pvalues.reshape(-1, 1), 5)\n",
    "lower_ConfInt95 = np.round(lower_ConfInt95.reshape(-1, 1), 5)\n",
    "upper_ConfInt95 = np.round(upper_ConfInt95.reshape(-1, 1), 5)\n",
    "\n",
    "frontier = np.concatenate(\n",
    "    [\n",
    "        theta[:4],\n",
    "        sterr[:4],\n",
    "        Zscores[:4],\n",
    "        Pvalues[:4],\n",
    "        lower_ConfInt95[:4],\n",
    "        upper_ConfInt95[:4],\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "mu = np.concatenate(\n",
    "    [\n",
    "        theta[4:6],\n",
    "        sterr[4:6],\n",
    "        Zscores[4:6],\n",
    "        Pvalues[4:6],\n",
    "        lower_ConfInt95[4:6],\n",
    "        upper_ConfInt95[4:6],\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "gamma = np.concatenate(\n",
    "    [theta[6], sterr[6], Zscores[6], Pvalues[6], lower_ConfInt95[6], upper_ConfInt95[6]]\n",
    ").T\n",
    "\n",
    "sigmas = np.concatenate(\n",
    "    [\n",
    "        theta[7:],\n",
    "        sterr[7:],\n",
    "        Zscores[7:],\n",
    "        Pvalues[7:],\n",
    "        lower_ConfInt95[7:],\n",
    "        upper_ConfInt95[7:],\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "print(\"\\nLL\", round(logMLE, 3))\n",
    "results.iloc[0:4, :] = frontier\n",
    "results.iloc[4, :] = np.full(shape=(1, 6), fill_value=\" \")\n",
    "results.iloc[5:7, :] = mu\n",
    "results.iloc[7, :] = np.full(shape=(1, 6), fill_value=\" \")\n",
    "results.iloc[8, :] = gamma\n",
    "results.iloc[9, :] = np.full(shape=(1, 6), fill_value=\" \")\n",
    "results.iloc[10:, :] = sigmas\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c3401ce7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])?  y\n"
     ]
    }
   ],
   "source": [
    "# Remove all previous function and variable definitions before the next exercise\n",
    "%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23dbbabc",
   "metadata": {},
   "source": [
    "## Exercise 4.9: TFE-G model\n",
    "\n",
    "This exercise 4.9 estimates the Fixed Effects SFM of Greene (2005a,b) using MLE for the _TaiwaneseManufacturing.csv_ data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "86c380f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numdifftools as nd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "def estimate(y, X, z1):\n",
    "    np.random.seed(10)\n",
    "    N, p = X.shape\n",
    "    # Starting values for MLE\n",
    "    alpha = 7.5\n",
    "    beta1 = 0.1\n",
    "    beta2 = 0.15\n",
    "    beta3_101 = stats.uniform.rvs(size=p - 2)\n",
    "    omega0 = -3.6\n",
    "    omega1 = 1.6  # Coefficient for z1\n",
    "    sigma2v = 0.085\n",
    "\n",
    "    # Initial parameter vector\n",
    "    theta0 = np.concatenate(\n",
    "        [\n",
    "            np.array([alpha, beta1, beta2]),\n",
    "            beta3_101,\n",
    "            np.array([omega0, omega1, sigma2v]),\n",
    "        ]\n",
    "    )\n",
    "    # Bounds to ensure Sigma2v and Sigma2v are positive\n",
    "    bounds = [(None, None) for x in range(len(theta0) - 1)] + [(1e-3, np.inf)]\n",
    "\n",
    "    MLE_results = minimize(\n",
    "        loglikelihood,\n",
    "        theta0,\n",
    "        method=\"L-BFGS-B\",\n",
    "        options={\"maxiter\": 10000, \"maxfun\": 20000, \"maxcor\": 100},\n",
    "        args=(y, X, z1),\n",
    "        bounds=bounds,\n",
    "    )\n",
    "\n",
    "    theta = MLE_results.x\n",
    "    logMLE = MLE_results.fun\n",
    "    # Estimate the hessian\n",
    "    hessian = nd.Hessian(f=loglikelihood, method=\"central\", step=1e-6)(theta, y, X, z1)\n",
    "\n",
    "    # Estimation of standard errors\n",
    "    ster = np.sqrt(np.diag(np.linalg.inv(hessian)))\n",
    "\n",
    "    return theta, ster, logMLE\n",
    "\n",
    "\n",
    "def loglikelihood(coefs, y, X, z1):\n",
    "    # Obtain the log-likelihood\n",
    "    logDen = log_density(coefs, y, X, z1)\n",
    "    log_likelihood = -np.sum(logDen)\n",
    "\n",
    "    return log_likelihood\n",
    "\n",
    "\n",
    "def log_density(coefs, y, X, z1):\n",
    "    N, p = X.shape\n",
    "    alpha = coefs[0]\n",
    "    beta1 = coefs[1]\n",
    "    beta2 = coefs[2]\n",
    "    beta3_101 = coefs[3 : 3 + p - 3 + 1]\n",
    "    omega0 = coefs[-3]\n",
    "    omega1 = coefs[-2]\n",
    "    sigma2v = coefs[-1]\n",
    "\n",
    "    sigma2u = np.exp(omega0 + omega1 * z1)\n",
    "    lambda_ = np.sqrt(sigma2u / sigma2v)\n",
    "    sigma2 = sigma2u + sigma2v\n",
    "    sigma = np.sqrt(sigma2)\n",
    "    eps = y - alpha - X[:, 0] * beta1 - X[:, 1] * beta2 - X[:, 2:] @ beta3_101\n",
    "\n",
    "    Den = (\n",
    "        2\n",
    "        / sigma\n",
    "        * stats.norm.pdf(eps / sigma, 0, 1)\n",
    "        * stats.norm.cdf(-lambda_ * eps / sigma, 0, 1)\n",
    "    )\n",
    "    Den = np.where(\n",
    "        np.abs(Den) < 1e-5, 1e-5, Den\n",
    "    )  # Adjust small densities for numerical precision\n",
    "    logDen = np.log(Den)  # Log density\n",
    "\n",
    "    return logDen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1ae5bafe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LL 183.842\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Est</th>\n",
       "      <th>StEr</th>\n",
       "      <th>t-stat</th>\n",
       "      <th>p-val</th>\n",
       "      <th>[95%Conf.</th>\n",
       "      <th>Interv]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>$$\\beta_{0}$$</th>\n",
       "      <td>0.776</td>\n",
       "      <td>0.136</td>\n",
       "      <td>5.718</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.51</td>\n",
       "      <td>1.042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x1</th>\n",
       "      <td>0.523</td>\n",
       "      <td>0.014</td>\n",
       "      <td>36.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x2</th>\n",
       "      <td>0.677</td>\n",
       "      <td>0.014</td>\n",
       "      <td>47.726</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$$\\omega_{0}$$</th>\n",
       "      <td>-3.603</td>\n",
       "      <td>0.524</td>\n",
       "      <td>-6.878</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.63</td>\n",
       "      <td>-2.576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>z1</th>\n",
       "      <td>1.659</td>\n",
       "      <td>0.277</td>\n",
       "      <td>5.995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.116</td>\n",
       "      <td>2.201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$$\\sigma^{2}_{v}$$</th>\n",
       "      <td>0.087</td>\n",
       "      <td>0.008</td>\n",
       "      <td>11.291</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Est   StEr  t-stat p-val [95%Conf. Interv]\n",
       "$$\\beta_{0}$$       0.776  0.136   5.718   0.0      0.51   1.042\n",
       "x1                  0.523  0.014   36.22   0.0     0.494   0.551\n",
       "x2                  0.677  0.014  47.726   0.0     0.649   0.704\n",
       "                                                                \n",
       "$$\\omega_{0}$$     -3.603  0.524  -6.878   0.0     -4.63  -2.576\n",
       "z1                  1.659  0.277   5.995   0.0     1.116   2.201\n",
       "$$\\sigma^{2}_{v}$$  0.087  0.008  11.291   0.0     0.072   0.102"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "production_data = pd.read_csv(r\"TaiwaneseManufacturing.csv\")\n",
    "id_dummies = pd.get_dummies(production_data[\"id\"], prefix=\"dum\", drop_first=True)\n",
    "\n",
    "y = production_data[\"y\"].values\n",
    "X = np.concatenate([production_data[[\"x1\", \"x2\"]].values, id_dummies.values], axis=1)\n",
    "z1 = production_data[\"z1\"].values\n",
    "\n",
    "# Estimate coefficients via MLE\n",
    "theta, sterr, logMLE = estimate(y, X, z1)\n",
    "\n",
    "Zscores = theta / sterr\n",
    "Pvalues = 2 * (1 - stats.norm.cdf(np.abs(Zscores)))\n",
    "lower_ConfInt95 = stats.norm.ppf(0.025, loc=theta, scale=sterr)\n",
    "upper_ConfInt95 = stats.norm.ppf(0.975, loc=theta, scale=sterr)\n",
    "\n",
    "# Display the results as a table\n",
    "results = pd.DataFrame(\n",
    "    columns=[\"Est\", \"StEr\", \"t-stat\", \"p-val\", \"[95%Conf.\", \"Interv]\"],\n",
    "    index=[\n",
    "        r\"$$\\beta_{0}$$\",\n",
    "        \"x1\",\n",
    "        \"x2\",\n",
    "        \" \",\n",
    "        r\"$$\\omega_{0}$$\",\n",
    "        r\"z1\",\n",
    "        r\"$$\\sigma^{2}_{v}$$\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "theta = np.round(theta.reshape(-1, 1), 3)\n",
    "sterr = np.round(sterr.reshape(-1, 1), 3)\n",
    "Zscores = np.round(Zscores.reshape(-1, 1), 3)\n",
    "Pvalues = np.round(Pvalues.reshape(-1, 1), 3)\n",
    "lower_ConfInt95 = np.round(lower_ConfInt95.reshape(-1, 1), 3)\n",
    "upper_ConfInt95 = np.round(upper_ConfInt95.reshape(-1, 1), 3)\n",
    "\n",
    "frontier = np.concatenate(\n",
    "    [\n",
    "        theta[:3],\n",
    "        sterr[:3],\n",
    "        Zscores[:3],\n",
    "        Pvalues[:3],\n",
    "        lower_ConfInt95[:3],\n",
    "        upper_ConfInt95[:3],\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "Omegas = np.concatenate(\n",
    "    [\n",
    "        theta[-3:-1],\n",
    "        sterr[-3:-1],\n",
    "        Zscores[-3:-1],\n",
    "        Pvalues[-3:-1],\n",
    "        lower_ConfInt95[-3:-1],\n",
    "        upper_ConfInt95[-3:-1],\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "sigmas = np.array(\n",
    "    [\n",
    "        theta[-1],\n",
    "        sterr[-1],\n",
    "        Zscores[-1],\n",
    "        Pvalues[-1],\n",
    "        lower_ConfInt95[-1],\n",
    "        upper_ConfInt95[-1],\n",
    "    ]\n",
    ").T\n",
    "\n",
    "print(\"\\nLL\", round(logMLE, 3))\n",
    "results.iloc[0:3, :] = frontier\n",
    "results.iloc[3, :] = np.full(shape=(1, 6), fill_value=\" \")\n",
    "results.iloc[4:6, :] = Omegas\n",
    "results.iloc[6:, :] = sigmas\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bf596139",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])?  y\n"
     ]
    }
   ],
   "source": [
    "# Remove all previous function and variable definitions before the next exercise\n",
    "%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329bc516",
   "metadata": {},
   "source": [
    "## Exercise 4.10: TRE-G model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "107e0604",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numdifftools as nd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy.optimize import minimize\n",
    "from statsmodels.tools import sequences\n",
    "\n",
    "\n",
    "def estimate(y, X):\n",
    "    np.random.seed(10)\n",
    "\n",
    "    # Starting values for MLE\n",
    "    alpha = 0.4\n",
    "    beta1 = 0.5\n",
    "    beta2 = 0.7\n",
    "    gamma0 = -3.1\n",
    "    gamma1 = 1.5\n",
    "    sigma2w = 0.4\n",
    "    sigma2v = 0.1\n",
    "\n",
    "    # Initial parameter vector\n",
    "    theta0 = np.array([alpha, beta1, beta2, gamma0, gamma1, sigma2w, sigma2v])\n",
    "    # Bounds to ensure Sigma22 and Sigma2v are positive\n",
    "    bounds = [(None, None) for x in range(len(theta0) - 2)] + [\n",
    "        (1e-3, np.inf),\n",
    "        (1e-3, np.inf),\n",
    "    ]\n",
    "\n",
    "    # random uniform variables for the simulated likelihood\n",
    "    halton_sequence = sequences.halton(dim=6, n_sample=100).T\n",
    "\n",
    "    MLE_results = minimize(\n",
    "        loglikelihood,\n",
    "        theta0,\n",
    "        method=\"L-BFGS-B\",\n",
    "        options={\"maxiter\": 10000, \"maxfun\": 20000, \"maxcor\": 100},\n",
    "        args=(y, X, halton_sequence),\n",
    "        bounds=bounds,\n",
    "    )\n",
    "    theta = MLE_results.x\n",
    "    logMLE = MLE_results.fun * -1\n",
    "\n",
    "    # Estimate the hessian\n",
    "    hessian = nd.Hessian(f=loglikelihood, method=\"central\", step=1e-6)(\n",
    "        theta, y, X, halton_sequence\n",
    "    )\n",
    "\n",
    "    # Estimation of standard errors\n",
    "    ster = np.sqrt(np.diag(np.linalg.inv(hessian)))\n",
    "\n",
    "    return theta, ster, logMLE\n",
    "\n",
    "\n",
    "def loglikelihood(coefs, y, X, halton_sequence):\n",
    "    # Obtain the log likelihood\n",
    "    logDen = log_density(coefs, y, X, halton_sequence)\n",
    "    log_likelihood = -np.sum(logDen)\n",
    "\n",
    "    return log_likelihood\n",
    "\n",
    "\n",
    "def log_density(coefs, y, X, halton_sequence):\n",
    "    alpha = coefs[0]\n",
    "    beta1 = coefs[1]\n",
    "    beta2 = coefs[2]\n",
    "    gamma0 = coefs[3]\n",
    "    gamma1 = coefs[4]\n",
    "    sigma2w = coefs[5]\n",
    "    sigma2v = coefs[6]\n",
    "\n",
    "    beta = np.array([beta1, beta2])\n",
    "    w = stats.norm.ppf(\n",
    "        halton_sequence, loc=0, scale=sigma2w\n",
    "    )  # simulated random variables\n",
    "\n",
    "    panels = np.unique(X[:, 0])\n",
    "    logDen_is = np.zeros(len(panels))\n",
    "    for j in range(len(panels)):\n",
    "        i = panels[j]\n",
    "        y_i = y[y[:, 0] == i, -1]\n",
    "        X_i = X[X[:, 0] == i, 1:3]\n",
    "        z_i = X[X[:, 0] == i, -1]\n",
    "\n",
    "        sigma2u = np.exp(gamma0 + gamma1 * z_i)\n",
    "        sigma2 = sigma2u + sigma2v\n",
    "        lam = np.sqrt(sigma2u) / np.sqrt(sigma2v)\n",
    "\n",
    "        X_i_beta = X_i @ beta\n",
    "        y_i_rep = np.repeat(y_i.reshape(-1, 1), 100, axis=1)\n",
    "        X_i_beta_rep = np.repeat(X_i_beta.reshape(-1, 1), 100, axis=1)\n",
    "        sigma2_rep = np.repeat(sigma2.reshape(-1, 1), 100, axis=1)\n",
    "        lam_rep = np.repeat(lam.reshape(-1, 1), 100, axis=1)\n",
    "\n",
    "        simulated_component_1 = np.mean(\n",
    "            np.log(\n",
    "                stats.norm.pdf(\n",
    "                    (y_i_rep - (alpha + w) - X_i_beta_rep) / np.sqrt(sigma2_rep)\n",
    "                )\n",
    "            ),\n",
    "            axis=1,\n",
    "        )\n",
    "        simulated_component_2 = np.mean(\n",
    "            np.log(\n",
    "                stats.norm.cdf(\n",
    "                    (lam_rep * (y_i_rep - (alpha + w) - X_i_beta_rep))\n",
    "                    / np.sqrt(sigma2_rep)\n",
    "                )\n",
    "            ),\n",
    "            axis=1,\n",
    "        )\n",
    "\n",
    "        LL_i = np.log(2 / sigma2) + simulated_component_1 + simulated_component_2\n",
    "        logDen_is[j] = np.sum(LL_i)\n",
    "\n",
    "    return logDen_is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4a6ceef4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Robert\\AppData\\Local\\Temp\\ipykernel_11668\\139070248.py:103: RuntimeWarning: divide by zero encountered in log\n",
      "  np.log(\n",
      "C:\\Users\\Robert\\Desktop\\EPA-Copula-SFA-website-main\\venv\\lib\\site-packages\\scipy\\optimize\\_numdiff.py:576: RuntimeWarning: invalid value encountered in subtract\n",
      "  df = fun(x) - f0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LL -337.505\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Est</th>\n",
       "      <th>StEr</th>\n",
       "      <th>t-stat</th>\n",
       "      <th>p-val</th>\n",
       "      <th>[95%Conf.</th>\n",
       "      <th>Interv]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>$$\\beta_{0}$$</th>\n",
       "      <td>0.068</td>\n",
       "      <td>0.033</td>\n",
       "      <td>2.084</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x1</th>\n",
       "      <td>0.502</td>\n",
       "      <td>0.027</td>\n",
       "      <td>18.667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x2</th>\n",
       "      <td>0.681</td>\n",
       "      <td>0.024</td>\n",
       "      <td>27.983</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.633</td>\n",
       "      <td>0.728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$$\\sigma^{2}_{u}$$</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$$\\gamma_{0}$$</th>\n",
       "      <td>-3.199</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-12.792</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.689</td>\n",
       "      <td>-2.709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>z1</th>\n",
       "      <td>1.386</td>\n",
       "      <td>0.234</td>\n",
       "      <td>5.922</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.928</td>\n",
       "      <td>1.845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$$\\sigma^{2}_{v}$$</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.969</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$$\\sigma^{2}_{w}$$</th>\n",
       "      <td>0.354</td>\n",
       "      <td>0.06</td>\n",
       "      <td>5.903</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Est   StEr  t-stat  p-val [95%Conf. Interv]\n",
       "$$\\beta_{0}$$       0.068  0.033   2.084  0.037     0.004   0.132\n",
       "x1                  0.502  0.027  18.667    0.0      0.45   0.555\n",
       "x2                  0.681  0.024  27.983    0.0     0.633   0.728\n",
       "$$\\sigma^{2}_{u}$$                                               \n",
       "$$\\gamma_{0}$$     -3.199   0.25 -12.792    0.0    -3.689  -2.709\n",
       "z1                  1.386  0.234   5.922    0.0     0.928   1.845\n",
       "                                                                 \n",
       "$$\\sigma^{2}_{v}$$  0.001  0.026   0.039  0.969     -0.05   0.052\n",
       "$$\\sigma^{2}_{w}$$  0.354   0.06   5.903    0.0     0.236   0.472"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "production_data = pd.read_csv(r\"TaiwaneseManufacturing.csv\")\n",
    "y = production_data[[\"id\", \"y\"]].values\n",
    "X = production_data[[\"id\", \"x1\", \"x2\", \"z1\"]].values\n",
    "\n",
    "# Estimate coefficients via MLE\n",
    "theta, sterr, logMLE = estimate(y, X)\n",
    "\n",
    "Zscores = theta / sterr\n",
    "Pvalues = 2 * (1 - stats.norm.cdf(np.abs(Zscores)))\n",
    "lower_ConfInt95 = stats.norm.ppf(0.025, loc=theta, scale=sterr)\n",
    "upper_ConfInt95 = stats.norm.ppf(0.975, loc=theta, scale=sterr)\n",
    "\n",
    "# Display the results as a table\n",
    "results = pd.DataFrame(\n",
    "    columns=[\"Est\", \"StEr\", \"t-stat\", \"p-val\", \"[95%Conf.\", \"Interv]\"],\n",
    "    index=[\n",
    "        r\"$$\\beta_{0}$$\",\n",
    "        \"x1\",\n",
    "        \"x2\",\n",
    "        \"$$\\sigma^{2}_{u}$$\",\n",
    "        \"$$\\gamma_{0}$$\",\n",
    "        \"z1\",\n",
    "        \" \",\n",
    "        r\"$$\\sigma^{2}_{v}$$\",\n",
    "        r\"$$\\sigma^{2}_{w}$$\",\n",
    "    ],\n",
    ")\n",
    "theta = np.round(theta.reshape(-1, 1), 3)\n",
    "sterr = np.round(sterr.reshape(-1, 1), 3)\n",
    "Zscores = np.round(Zscores.reshape(-1, 1), 3)\n",
    "Pvalues = np.round(Pvalues.reshape(-1, 1), 3)\n",
    "lower_ConfInt95 = np.round(lower_ConfInt95.reshape(-1, 1), 3)\n",
    "upper_ConfInt95 = np.round(upper_ConfInt95.reshape(-1, 1), 3)\n",
    "\n",
    "frontier = np.concatenate(\n",
    "    [\n",
    "        theta[:3],\n",
    "        sterr[:3],\n",
    "        Zscores[:3],\n",
    "        Pvalues[:3],\n",
    "        lower_ConfInt95[:3],\n",
    "        upper_ConfInt95[:3],\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "Gammas = np.concatenate(\n",
    "    [\n",
    "        theta[3:5],\n",
    "        sterr[3:5],\n",
    "        Zscores[3:5],\n",
    "        Pvalues[3:5],\n",
    "        lower_ConfInt95[3:5],\n",
    "        upper_ConfInt95[3:5],\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "sigmas = np.concatenate(\n",
    "    [\n",
    "        theta[-2:],\n",
    "        sterr[-2:],\n",
    "        Zscores[-2:],\n",
    "        Pvalues[-2:],\n",
    "        lower_ConfInt95[-2:],\n",
    "        upper_ConfInt95[-2:],\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "print(\"\\nLL\", round(logMLE, 3))\n",
    "results.iloc[0:3, :] = frontier\n",
    "results.iloc[3, :] = np.full(shape=(1, 6), fill_value=\" \")\n",
    "results.iloc[4:6, :] = Gammas\n",
    "results.iloc[6, :] = np.full(shape=(1, 6), fill_value=\" \")\n",
    "results.iloc[7:, :] = sigmas\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ddb1a829",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])?  y\n"
     ]
    }
   ],
   "source": [
    "# Remove all previous function and variable definitions before the next exercise\n",
    "%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f9db8e",
   "metadata": {},
   "source": [
    "## Exercise 4.11: \"True\" Fixed Effects model of Wang and Ho (2010)\n",
    "\n",
    "This exercise estimates the fixed effects stochastic frontier model of Wang and Ho (2010) using MLE for the _TaiwaneseManufacturing.csv_ data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d14a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numdifftools as nd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "def estimate(y, X):\n",
    "    np.random.seed(10)\n",
    "    N, p = X.shape\n",
    "\n",
    "    # Starting values for MLE\n",
    "    beta1 = 0.53\n",
    "    beta2 = 0.68\n",
    "    gamma = 0.53  # Coefficient for z1\n",
    "    sigma2u = 0.15\n",
    "    sigma2v = 0.1\n",
    "\n",
    "    # Initial parameter vector\n",
    "    theta0 = np.array([beta1, beta2, gamma, sigma2u, sigma2v])\n",
    "    # Bounds to ensure Sigma2v and Sigma2v are positive\n",
    "    bounds = [(None, None) for x in range(len(theta0) - 2)] + [\n",
    "        (1e-3, np.inf),\n",
    "        (1e-3, np.inf),\n",
    "    ]\n",
    "\n",
    "    MLE_results = minimize(\n",
    "        loglikelihood,\n",
    "        theta0,\n",
    "        method=\"L-BFGS-B\",\n",
    "        options={\"maxiter\": 1000, \"maxfun\": 10000, \"maxcor\": 100},\n",
    "        args=(y, X),\n",
    "        bounds=bounds,\n",
    "    )\n",
    "\n",
    "    theta = MLE_results.x\n",
    "    logMLE = MLE_results.fun\n",
    "\n",
    "    # Estimate the hessian\n",
    "    hessian = nd.Hessian(f=loglikelihood, method=\"central\", step=1e-5)(theta, y, X)\n",
    "\n",
    "    # Estimation of standard errors\n",
    "    ster = np.sqrt(np.diag(np.linalg.inv(hessian)))\n",
    "\n",
    "    return theta, ster, logMLE\n",
    "\n",
    "\n",
    "def loglikelihood(coefs, y, X):\n",
    "    # Obtain the log-likelihood\n",
    "    logDen = log_density(coefs, y, X)\n",
    "    log_likelihood = -np.sum(logDen)\n",
    "\n",
    "    return log_likelihood\n",
    "\n",
    "\n",
    "def log_density(coefs, y, X):\n",
    "    beta1 = coefs[0]\n",
    "    beta2 = coefs[1]\n",
    "    gamma = coefs[2]\n",
    "    sigma2_u = coefs[3]\n",
    "    sigma2_v = coefs[4]\n",
    "\n",
    "    beta = np.array([beta1, beta2])\n",
    "    Sigma = np.zeros((5, 5))\n",
    "    for i in range(5):\n",
    "        for j in range(5):\n",
    "            if j == i - 1:\n",
    "                Sigma[i, j] = -sigma2_v\n",
    "            elif i == j:\n",
    "                Sigma[i, j] = 2 * sigma2_v\n",
    "            elif j == i + 1:\n",
    "                Sigma[i, j] = -sigma2_v\n",
    "\n",
    "    panels = np.unique(X[:, 0])\n",
    "    logDen_is = np.zeros(len(panels))\n",
    "    for j in range(len(panels)):\n",
    "        i = panels[j]\n",
    "        y_i = y[y[:, 0] == i, -1]\n",
    "        X_i = X[X[:, 0] == i, 1:3]\n",
    "        z_i = X[X[:, 0] == i, -1]\n",
    "        T = len(X_i)\n",
    "\n",
    "        delta_y_i = np.diff(y_i)\n",
    "        delta_X_i = np.diff(X_i, axis=0)\n",
    "        delta_eps_i = delta_y_i - delta_X_i @ beta\n",
    "        h_i = z_i * gamma\n",
    "        delta_h_i = np.diff(h_i)\n",
    "        sigma2_stari = sigma2_u / (\n",
    "            sigma2_u * delta_h_i.T @ np.linalg.inv(Sigma) @ delta_h_i + 1\n",
    "        )\n",
    "        mu_i_star = 0 - (sigma2_u * delta_eps_i @ np.linalg.inv(Sigma) @ delta_h_i) / (\n",
    "            sigma2_u * delta_h_i.T @ np.linalg.inv(Sigma) @ delta_h_i + 1\n",
    "        )\n",
    "\n",
    "        LL_i = (\n",
    "            np.log(\n",
    "                np.sqrt(sigma2_stari)\n",
    "                * stats.norm.cdf(mu_i_star / np.sqrt(sigma2_stari))\n",
    "            )\n",
    "            - 0.5\n",
    "            * (\n",
    "                delta_eps_i @ np.linalg.inv(Sigma) @ delta_eps_i\n",
    "                + (0 / np.sqrt(sigma2_u)) ** 2\n",
    "                - (mu_i_star / np.sqrt(sigma2_stari)) ** 2\n",
    "            )\n",
    "            - (T - 1) * np.log(np.sqrt(sigma2_v))\n",
    "            - np.log(np.sqrt(sigma2_u) * stats.norm.cdf(0 / np.sqrt(sigma2_u)))\n",
    "        )\n",
    "        logDen_is[j] = LL_i\n",
    "\n",
    "    return logDen_is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "dfd1a225",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LL -265.28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Est</th>\n",
       "      <th>StEr</th>\n",
       "      <th>z-stat</th>\n",
       "      <th>p-val</th>\n",
       "      <th>[95%Conf.</th>\n",
       "      <th>Interv]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>x1</th>\n",
       "      <td>0.521</td>\n",
       "      <td>0.015</td>\n",
       "      <td>34.112</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.491</td>\n",
       "      <td>0.551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x2</th>\n",
       "      <td>0.691</td>\n",
       "      <td>0.015</td>\n",
       "      <td>46.183</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.662</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>z1</th>\n",
       "      <td>0.56</td>\n",
       "      <td>26.453</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.992</td>\n",
       "      <td>-51.287</td>\n",
       "      <td>52.407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$$\\sigma^{2}_{v}$$</th>\n",
       "      <td>0.2</td>\n",
       "      <td>18.861</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.992</td>\n",
       "      <td>-36.768</td>\n",
       "      <td>37.167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$$\\sigma^{2}_{w}$$</th>\n",
       "      <td>0.111</td>\n",
       "      <td>0.008</td>\n",
       "      <td>14.727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Est    StEr  z-stat  p-val [95%Conf. Interv]\n",
       "x1                  0.521   0.015  34.112    0.0     0.491   0.551\n",
       "x2                  0.691   0.015  46.183    0.0     0.662    0.72\n",
       "                                                                  \n",
       "z1                   0.56  26.453   0.021  0.992   -51.287  52.407\n",
       "$$\\sigma^{2}_{v}$$    0.2  18.861   0.011  0.992   -36.768  37.167\n",
       "$$\\sigma^{2}_{w}$$  0.111   0.008  14.727    0.0     0.096   0.126"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "production_data = pd.read_csv(r\"TaiwaneseManufacturing.csv\")\n",
    "\n",
    "y = production_data[[\"id\", \"y\"]].values\n",
    "X = production_data[[\"id\", \"x1\", \"x2\", \"z1\"]].values\n",
    "\n",
    "theta, sterr, logMLE = estimate(y, X)\n",
    "\n",
    "Zscores = theta / sterr\n",
    "Pvalues = 2 * (1 - stats.norm.cdf(np.abs(Zscores)))\n",
    "lower_ConfInt95 = stats.norm.ppf(0.025, loc=theta, scale=sterr)\n",
    "upper_ConfInt95 = stats.norm.ppf(0.975, loc=theta, scale=sterr)\n",
    "\n",
    "# Display the results as a table\n",
    "results = pd.DataFrame(\n",
    "    columns=[\"Est\", \"StEr\", \"z-stat\", \"p-val\", \"[95%Conf.\", \"Interv]\"],\n",
    "    index=[\n",
    "        \"x1\",\n",
    "        \"x2\",\n",
    "        \" \",\n",
    "        \"z1\",\n",
    "        r\"$$\\sigma^{2}_{v}$$\",\n",
    "        r\"$$\\sigma^{2}_{w}$$\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "theta = np.round(theta.reshape(-1, 1), 3)\n",
    "sterr = np.round(sterr.reshape(-1, 1), 3)\n",
    "Zscores = np.round(Zscores.reshape(-1, 1), 3)\n",
    "Pvalues = np.round(Pvalues.reshape(-1, 1), 3)\n",
    "lower_ConfInt95 = np.round(lower_ConfInt95.reshape(-1, 1), 3)\n",
    "upper_ConfInt95 = np.round(upper_ConfInt95.reshape(-1, 1), 3)\n",
    "\n",
    "frontier = np.concatenate(\n",
    "    [\n",
    "        theta[:2],\n",
    "        sterr[:2],\n",
    "        Zscores[:2],\n",
    "        Pvalues[:2],\n",
    "        lower_ConfInt95[:2],\n",
    "        upper_ConfInt95[:2],\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "deltas = np.concatenate(\n",
    "    [\n",
    "        theta[2],\n",
    "        sterr[2],\n",
    "        Zscores[2],\n",
    "        Pvalues[-2],\n",
    "        lower_ConfInt95[2],\n",
    "        upper_ConfInt95[2],\n",
    "    ]\n",
    ")\n",
    "sigmas = np.array(\n",
    "    [\n",
    "        theta[-2:],\n",
    "        sterr[-2:],\n",
    "        Zscores[-2:],\n",
    "        Pvalues[-2:],\n",
    "        lower_ConfInt95[-2:],\n",
    "        upper_ConfInt95[-2:],\n",
    "    ]\n",
    ").T\n",
    "\n",
    "print(\"\\nLL\", round(logMLE, 3))\n",
    "results.iloc[0:2, :] = frontier\n",
    "results.iloc[2, :] = np.full(shape=(1, 6), fill_value=\" \")\n",
    "results.iloc[3:4, :] = deltas\n",
    "results.iloc[4:, :] = sigmas\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820972ab",
   "metadata": {},
   "source": [
    "## Exercise 4.12: KLH model of Kumbhakar et al. (2014)\n",
    "\n",
    "This exercise estimates the model of Kumbhakar et al. (2014) that allows for both persistent and time varying inefficiency for the _TaiwaneseManufacturing.csv_ data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "518e658a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numdifftools as nd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from linearmodels import (\n",
    "    RandomEffects,  # To install the linear models package run: pip install linearmodels at the Anaconda prompt\n",
    ")\n",
    "from scipy import stats\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "def loglikelihood(coefs, y, x1):\n",
    "    # Obtain the log likelihood\n",
    "    logDen = log_density(coefs, y, x1)\n",
    "    log_likelihood = -np.sum(logDen)\n",
    "\n",
    "    return log_likelihood\n",
    "\n",
    "\n",
    "def log_density(coefs, y, x1):\n",
    "    # Get parameters\n",
    "    beta1 = coefs[0]\n",
    "    sigma2u = coefs[1]\n",
    "    sigma2v = coefs[2]\n",
    "    Lambda = np.sqrt(sigma2u / sigma2v)\n",
    "    sigma2 = sigma2u + sigma2v\n",
    "    sigma = np.sqrt(sigma2)\n",
    "\n",
    "    # Composed errors from the production function equation\n",
    "    eps = y - x1 * beta1\n",
    "\n",
    "    # Compute the log density\n",
    "    Den = (\n",
    "        (2 / sigma)\n",
    "        * stats.norm.pdf(eps / sigma)\n",
    "        * stats.norm.cdf(-Lambda * eps / sigma)\n",
    "    )\n",
    "    logDen = np.log(Den)\n",
    "\n",
    "    return logDen\n",
    "\n",
    "\n",
    "def BC98_TE(theta, y, x1):\n",
    "    beta1 = theta[0]\n",
    "    sigma2u = theta[1]\n",
    "    sigma2v = theta[2]\n",
    "\n",
    "    sigma2 = sigma2u + sigma2v\n",
    "    epsilon = y - x1 * beta1\n",
    "    u_star = (-sigma2u * epsilon) / (sigma2)\n",
    "    sigma2_star = (sigma2v * sigma2u) / (sigma2v + sigma2u)\n",
    "\n",
    "    TE = np.exp(-u_star + 0.5 * sigma2_star) * (\n",
    "        stats.norm.cdf((u_star / np.sqrt(sigma2_star)) - np.sqrt(sigma2_star))\n",
    "        / stats.norm.cdf(u_star / np.sqrt(sigma2_star))\n",
    "    )\n",
    "\n",
    "    return TE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "95e4985c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>50%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>o_TE</th>\n",
       "      <td>600.0</td>\n",
       "      <td>0.548567</td>\n",
       "      <td>0.146164</td>\n",
       "      <td>0.032409</td>\n",
       "      <td>0.557264</td>\n",
       "      <td>0.842603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pers_TE</th>\n",
       "      <td>600.0</td>\n",
       "      <td>0.785849</td>\n",
       "      <td>0.102432</td>\n",
       "      <td>0.427305</td>\n",
       "      <td>0.801106</td>\n",
       "      <td>0.927208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tv_TE</th>\n",
       "      <td>600.0</td>\n",
       "      <td>0.690615</td>\n",
       "      <td>0.138213</td>\n",
       "      <td>0.058205</td>\n",
       "      <td>0.712146</td>\n",
       "      <td>0.910178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         count      mean       std       min       50%       max\n",
       "o_TE     600.0  0.548567  0.146164  0.032409  0.557264  0.842603\n",
       "pers_TE  600.0  0.785849  0.102432  0.427305  0.801106  0.927208\n",
       "tv_TE    600.0  0.690615  0.138213  0.058205  0.712146  0.910178"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "production_data = pd.read_csv(r\"TaiwaneseManufacturing.csv\")\n",
    "\n",
    "# Estimate the fixed effects rgeression model\n",
    "production_data = production_data.set_index(keys=[\"id\", \"time\"], drop=False)\n",
    "production_data[\"intercept\"] = 1\n",
    "onee = np.ones(len(production_data))\n",
    "\n",
    "RE_model = RandomEffects(\n",
    "    production_data[\"y\"], production_data[[\"intercept\", \"x1\", \"x2\"]]\n",
    ")\n",
    "RE_result = RE_model.fit()\n",
    "\n",
    "alphai = production_data[\"y\"].values - (\n",
    "    production_data[[\"intercept\", \"x1\", \"x2\"]].values @ RE_result.params.values\n",
    "    + RE_result.resids.values.flatten()\n",
    ")\n",
    "error = RE_result.resids.values.flatten()\n",
    "combined_error = error + alphai\n",
    "\n",
    "# First step MLE\n",
    "beta1 = 0.36\n",
    "sigma2u = 0.21\n",
    "sigma2v = 0.073\n",
    "\n",
    "# Initial parameter vector\n",
    "theta0 = np.array([beta1, sigma2u, sigma2v])\n",
    "\n",
    "# Bounds to ensure Sigma2v and Sigma2v are positive\n",
    "bounds = [(None, None) for x in range(len(theta0) - 2)] + [\n",
    "    (1e-3, np.inf),\n",
    "    (1e-3, np.inf),\n",
    "]\n",
    "\n",
    "x1 = onee\n",
    "MLE_results1 = minimize(\n",
    "    loglikelihood,\n",
    "    theta0,\n",
    "    method=\"L-BFGS-B\",\n",
    "    options={\"maxiter\": 1000, \"maxfun\": 10000, \"maxcor\": 100},\n",
    "    args=(error, x1),\n",
    "    bounds=bounds,\n",
    ")\n",
    "theta1 = MLE_results1.x\n",
    "logMLE1 = MLE_results1.fun\n",
    "\n",
    "tv_TE = BC98_TE(theta=theta1, y=error, x1=x1)\n",
    "\n",
    "# Second step MLE\n",
    "beta1 = 0.36\n",
    "sigma2u = 0.2\n",
    "sigma2v = 0.06\n",
    "# Initial parameter vector\n",
    "theta0 = np.array([beta1, sigma2u, sigma2v])\n",
    "\n",
    "# Bounds to ensure Sigma2v and Sigma2v are positive\n",
    "bounds = [(None, None) for x in range(len(theta0) - 2)] + [\n",
    "    (1e-3, np.inf),\n",
    "    (1e-3, np.inf),\n",
    "]\n",
    "\n",
    "MLE_results2 = minimize(\n",
    "    loglikelihood,\n",
    "    theta0,\n",
    "    method=\"L-BFGS-B\",\n",
    "    options={\"maxiter\": 1000, \"maxfun\": 10000, \"maxcor\": 100},\n",
    "    args=(alphai, x1),\n",
    "    bounds=bounds,\n",
    ")\n",
    "theta2 = MLE_results2.x\n",
    "logMLE2 = MLE_results2.fun\n",
    "\n",
    "pers_TE = BC98_TE(theta=theta2, y=alphai, x1=x1)\n",
    "\n",
    "o_TE = pers_TE * tv_TE\n",
    "\n",
    "TE_matrix = pd.DataFrame(data={\"o_TE\": o_TE, \"pers_TE\": pers_TE, \"tv_TE\": tv_TE})\n",
    "\n",
    "display(TE_matrix.describe(percentiles=[]).T)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
